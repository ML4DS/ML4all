{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab of data analysis with python\n",
    "\n",
    "    Author: Jesús Fernández Bes\n",
    "            Jerónimo Arenas García (jeronimo.arenas@uc3m.es)\n",
    "            Jesús Cid Sueiro (jcid@tsc.uc3m.es)\n",
    "\n",
    "    Notebook version: 1.1 (Sep 20, 2017)\n",
    "\n",
    "    Changes: v.1.0 - First version.\n",
    "             v.1.1 - Compatibility with python 2 and python 3\n",
    "\n",
    "    Pending changes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will introduce some of the modules that we will use in the rest of the labs of the course.\n",
    "\n",
    "The usual beginning of any python module is a list of import statements. In most our file we will use the following modules:\n",
    "\n",
    "* numpy: The basic scientific computing library.\n",
    "* csv: Used for input/output in using comma separated values files, one of the standards formats in data management.\n",
    "* matplotlib: Used for plotting figures and graphs\n",
    "* sklearn: Scikit-learn is the machine learning library for python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Needed to include the figures in this notebook, you can remove it\n",
    "# to work with a normal script\n",
    "    \n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NUMPY \n",
    "\n",
    "The _numpy_ module is useful for scientific computing in Python.\n",
    "\n",
    "The main data structure in _numpy_ is the n-dimensional array. You can define a _numpy_ _array_ from a list or a list of lists. Python will try to build it with the appropiate dimensions. You can check the dimensions of the array with _shape()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.array([[1, 2],[3, 4]])\n",
    "print(my_array)\n",
    "print(np.shape(my_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a new 3x2 array named *my_array2* with  [1, 2, 3] in the first row and [4,5,6] in the second.\n",
    "Check the dimension of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of operations you can do with numpy arrays similar to the ones you can do with matrices in Matlab. One os the most important is **slicing**. We saw it when we talked about lists, it consists in extracting some subarray of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array3 = my_array[:,1]\n",
    "print(my_array3)\n",
    "print(my_array[1,0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important thing to consider when you do slicing are the dimensions of the output array. Check the shape of *my_array3*. Check also its dimension with function _ndim_: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have correctly computed it you will see that *my_array3* is one dimensional. Sometimes this can be a problem when you are working with 2D matrixes (and vectors can be considered as 2D matrixes with one of the sizes equal to 1). To solve this, _numpy_ provides the _newaxis_ constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array3 = my_array3[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check again the shape and dimension of *my_array3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to extract a single row or column from a 2D numpy array so that the result is still 2D, without explictly recurring to _np.newaxis_. Compare the outputs of the following print commands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_array[:,1])\n",
    "print(my_array[:,1].shape)\n",
    "print(my_array[:,1:2])\n",
    "print(my_array[:,1:2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important array manipulation method is array _concatenation_ or _stacking_. It is useful to always state explicitly in which direction we want to stack the arrays. For example in the following example we are stacking the arrays vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_array)\n",
    "print(my_array2)\n",
    "print(np.concatenate( (my_array, my_array2) , axis=1)) # columnwise concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Concatenate the first column of *my_array* and the second column of *my_array2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create _numpy_ arrays in several ways, not only from lists. For example _numpy_ provides a number of functions to create special types of matrices. \n",
    "\n",
    "**EXERCISE:** Create 3 arrays usings _ones_, _zeros_ and _eye_. If you have any doubt about the parameters of the functions have a look at the help with the function _help( )_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally _numpy_ provides all the basic matrix operations: multiplications, dot products, ...\n",
    "You can find information about them in the [Numpy manual](http://docs.scipy.org/doc/numpy/reference/).\n",
    "\n",
    "In addition to _numpy_ we have a more advanced library for scientific computing, [Scipy](http://www.scipy.org/scipylib/index.html), that includes modules for linear algebra, signal processing, Fourier transform, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Matplotlib\n",
    "\n",
    "One important step of data analysis is data visualization. In python the simplest plotting library is _matplotlib_ and its sintax is similar to Matlab plotting library. In the next example we plot two sinusoids with different simbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0.0, 1.0, 0.05)\n",
    "a1 = np.sin(2*np.pi*t)\n",
    "a2 = np.sin(4*np.pi*t)\n",
    "#s = sin(2*3.14159*t)\n",
    "\n",
    "plt.figure()\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.plot(t,a1)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('a_1(t)')\n",
    "ax2 = plt.subplot(212)\n",
    "ax2.plot(t,a2, 'r.')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('a_2(t)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification example\n",
    "\n",
    "\n",
    "One of the main machine learning problems is clasification. In the following example, we will load and visualize a dataset that can be used in a clasification problem.\n",
    "\n",
    "The [iris dataset](https://archive.ics.uci.edu/ml/datasets/Iris) is one of the most popular pattern recognition datasets. It consists on 150 instances of 4 features of iris flowers:\n",
    "\n",
    "1. sepal length in cm\n",
    "2. sepal width in cm\n",
    "3. petal length in cm\n",
    "4. petal width in cm\n",
    "\n",
    "The objective is usually to distinguish three different classes of iris plant: Iris setosa, Iris versicolor, and Iris virginica.\n",
    "\n",
    "### 3.1 Loading the data\n",
    "\n",
    "We give you the data in _.csv_ format. In each line of the csv file we have the 4 real-valued features of each instance and then a string defining the class of that instance: Iris-setosa, Iris-versicolor or Iris-virginica. There are 150 instances of flowers in the csv file. \n",
    "\n",
    "Let's se how we can load the data in an _array_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open up the csv file in to a Python object\n",
    "csv_file_object = csv.reader(open('iris_data.csv', 'r')) \n",
    "datalist = []                    # Create a variable called 'data'.\n",
    "for row in csv_file_object:      # Run through each row in the csv file,\n",
    "\n",
    "    datalist.append(row)         # adding each row to the data variable\n",
    "\n",
    "\n",
    "data = np.array(datalist)  # Then convert from a list to an array\n",
    "                           # Be aware that each item is currently\n",
    "                           # a string in this format\n",
    "print(np.shape(data))\n",
    "X = data[:,0:-1]\n",
    "label = data[:,-1,np.newaxis]\n",
    "print(X.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous code we have saved the features in matrix X and the class labels in the vector labels. Both are 2D _numpy_ _arrays_.\n",
    "We are also printing the shapes of each variable (see that we can also use `array_name.shape` to get the shape, appart from function _shape()_). Checking the shape of matrices is a convenient way to prevent mistakes in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualizing the data\n",
    "\n",
    "Extract the 2 first features of the data (sepal length and width) and plot the first versus the second in a figure, use a different color for the data corresponding to different classes.\n",
    "\n",
    "First of all you probably want to split the data according to each class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this plot, which classes seem more difficult to distinguish?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regression example\n",
    "\n",
    "\n",
    "Now that we know how to load some data and visualize them, we will try to solve a simple regression task.\n",
    "\n",
    "Our objective in this example is to predict the crime rates in different areas of the US using some socio-demographic data.\n",
    "\n",
    "This dataset has 127 socioeconomic variables of different nature: categorical, integer, real, and for some of them there are also missing data ([check wikipedia](https://en.wikipedia.org/wiki/Missing_data)). This is usually a problem when training machine learning models, but we will ignore that problem and take only a small number of variables that we think can be useful for regression and which have no missing values.\n",
    "\n",
    "5. population: population for community\n",
    "6. householdsize: mean people per household\n",
    "17. medIncome: median household income \n",
    "\n",
    "The objective in the regresion problem is another real value that contains the *total number of violent crimes per 100K population*.\n",
    "\n",
    "### 4.1 Loading the data\n",
    "\n",
    "First of all, load the data from file _communities.csv_ in a new array. This array should have 1994 rows (instances) and 128 columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the columns (5,6,17) of the data and save them in a matrix *X_com*. This will be our input data. Convert this array into a _float_ array. The shape should be (1994,3) \n",
    "\n",
    "Get the last column of the data and save it in an array called *y_com*. Convert this matrix into a _float_ array.\n",
    "Check that the shape is (1994,1) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot each variable in *X_com* versus *y_com* to have a first (partial) view of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train/Test splitting\n",
    "\n",
    "Now, we are about to start doing machine learning. But, first of all, we have to separate our data in train and test partitions.\n",
    "\n",
    "The train data will be used to adjust the parameters (train) of our model.\n",
    "The test data will be used to evaluate our model.\n",
    "\n",
    "Use *sklearn.cross_validation.train_test_split* to split the data in *train* (60%) and *test* (40%). Save the results in variables named *X_train*, *X_test*, *y_train*, *y_test*.\n",
    "\n",
    "#### Important note\n",
    "In real applications, you would have no access to any targets for the test data. However, for illustratory purposes, when evaluating machine learning algorithms it is common to set aside a _test partition_, including the corresponding labels, so that you can use these targets to assess the performance of the method. When proceeding in this way, the test labels should never be used during the design. It is just allowed to use them as a final assessment step once the classifier or regression model has been fully adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3  Normalization\n",
    "\n",
    "Most machine learning algorithms require that the data is standardized (mean=0, standard deviation= 1). Scikit-learn provides a tool to do that in the object _sklearn.preprocessing.StandardScaler_ (but you can also try and program it by yourself, it easier than in MATLAB!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Training\n",
    "\n",
    "We will apply two different K-NN regressors for this example. One with K (*n_neighbors*) = 1 and the other with K=7.\n",
    "\n",
    "Read the [API](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) and [this example](http://scikit-learn.org/stable/auto_examples/neighbors/plot_regression.html#example-neighbors-plot-regression-py) to understand how to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Prediction and evaluation\n",
    "\n",
    "Now use the two models you have trained to predict the test output *y_test*. To evaluate it measure the MSE.\n",
    "\n",
    "The formula of MSE is\n",
    "\n",
    "$$\\text{MSE}=\\frac{1}{K}\\sum_{k=1}^{K}({\\hat{y}}-y)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Saving the results\n",
    "\n",
    "Finally we will save all our predictions for the model with K=1 in a csv file. To do so you can use the following code Snippet, where *y_pred* are the predicted output values for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
