{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "    Notebook version: 2.0 (Nov 21, 2017)\n",
    "                      2.1 (Oct 19, 2018)\n",
    "                      2.2 (Oct 09, 2019)\n",
    "\n",
    "    Author: Jesús Cid Sueiro (jcid@tsc.uc3m.es)\n",
    "            Jerónimo Arenas García (jarenas@tsc.uc3m.es)\n",
    "\n",
    "    Changes: v.1.0 - First version\n",
    "             v.1.1 - Typo correction. Prepared for slide presentation\n",
    "             v.2.0 - Prepared for Python 3.0 (backcompmatible with 2.7)\n",
    "                     Assumptions for regression model modified\n",
    "             v.2.1 - Minor changes regarding notation and assumptions\n",
    "             v.2.2 - Updated notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# To visualize plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Imported libraries\n",
    "import csv\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "### 1.1. Binary classification and decision theory. The MAP criterion\n",
    "\n",
    "The goal of a classification problem is to assign a *class* or *category* to every *instance* or *observation* of a data collection. Here, we will assume that every instance ${\\bf x}$ is an $N$-dimensional vector in $\\mathbb{R}^N$, and that the class $y$ of sample ${\\bf x}$ is an element of a binary set ${\\mathcal Y} = \\{0, 1\\}$. The goal of a classifier is to predict the true value of $y$ after observing ${\\bf x}$.\n",
    "\n",
    "We will denote as $\\hat{y}$ the classifier output or *decision*. If $y=\\hat{y}$, the decision is a *hit*, otherwise $y\\neq \\hat{y}$ and the decision is an *error*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Decision theory provides a solution to the classification problem in situations where the relation between instance ${\\bf x}$ and its class $y$ is given by a known probabilistic model: assume that every tuple $({\\bf x}, y)$ is an outcome of a random vector $({\\bf X}, Y)$ with joint distribution $p_{{\\bf X},Y}({\\bf x}, y)$. A natural criteria for classification is to select predictor $\\hat{Y}=f({\\bf x})$ in such a way that the probability or error, $P\\{\\hat{Y} \\neq Y\\}$ is minimum. Noting that\n",
    "\n",
    "$$\n",
    "P\\{\\hat{Y} \\neq Y\\} = \\int P\\{\\hat{Y} \\neq Y | {\\bf x}\\} p_{\\bf X}({\\bf x}) d{\\bf x}\n",
    "$$\n",
    "\n",
    "the optimal decision is got if, for every sample ${\\bf x}$, we make decision minimizing the conditional error probability:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y}^* &= \\arg\\min_{\\hat{y}} P\\{\\hat{y} \\neq Y |{\\bf x}\\} \\\\\n",
    "          &= \\arg\\max_{\\hat{y}} P\\{\\hat{y} = Y |{\\bf x}\\} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Thus, the optimal decision rule can be expressed as\n",
    "\n",
    "$$\n",
    "P_{Y|{\\bf X}}(1|{\\bf x}) \\quad\\mathop{\\gtrless}^{\\hat{y}=1}_{\\hat{y}=0}\\quad  P_{Y|{\\bf X}}(0|{\\bf x}) \n",
    "$$\n",
    "\n",
    "or, equivalently\n",
    "\n",
    "$$\n",
    "P_{Y|{\\bf X}}(1|{\\bf x}) \\quad\\mathop{\\gtrless}^{\\hat{y}=1}_{\\hat{y}=0}\\quad  \\frac{1}{2} \n",
    "$$\n",
    "\n",
    "The classifier implementing this decision rule is usually referred to as the MAP (*Maximum A Posteriori*) classifier. As we have seen, the MAP classifier minimizes the error probability for binary classification, but the result can also be generalized to multiclass classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.2. Parametric classification.\n",
    "\n",
    "Classical decision theory is grounded on the assumption that the probabilistic model relating the observed sample ${\\bf X}$ and the true hypothesis $Y$ is known. Unfortunately, this is unrealistic in many applications, where the only available information to construct the classifier is a dataset $\\mathcal D = \\{{\\bf x}_k, y_k\\}_{k=0}^{K-1}$ of instances and their respective class labels.\n",
    "\n",
    "A more realistic formulation of the classification problem is the following: given a dataset $\\mathcal D = \\{({\\bf x}_k, y_k) \\in {\\mathbb{R}}^N \\times {\\mathcal Y}, \\, k=0,\\ldots,{K-1}\\}$ of independent and identically distributed (i.i.d.) samples from an ***unknown*** distribution $p_{{\\bf X},Y}({\\bf x}, y)$, predict the class $y$ of a new sample ${\\bf x}$ with the minimum probability of error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Since the probabilistic model generating the data is unknown, the MAP decision rule cannot be applied. However, many classification algorithms use the dataset to obtain an estimate of the posterior class probabilities, and apply it to implement an approximation to the MAP decision maker.\n",
    "\n",
    "Parametric classifiers based on this idea assume, additionally, that the posterior class probabilty satisfies some parametric formula:\n",
    "\n",
    "$$\n",
    "P_{Y|X}(1|{\\bf x},{\\bf w}) = f_{\\bf w}({\\bf x})\n",
    "$$\n",
    "\n",
    "where ${\\bf w}$ is a vector of parameters. Given the expression of the MAP decision maker, classification consists in comparing the value of $f_{\\bf w}({\\bf x})$ with the threshold $\\frac{1}{2}$, and each parameter vector would be associated to a different decision maker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In practice, the dataset ${\\mathcal D}$ is used to select a particular parameter vector $\\hat{\\bf w}$ according to certain criterion. Accordingly, the decision rule becomes\n",
    "\n",
    "$$\n",
    "f_{\\hat{\\bf w}}({\\bf x}) \\quad\\mathop{\\gtrless}^{\\hat{y}=1}_{\\hat{y}=0}\\quad  \\frac{1}{2} \n",
    "$$\n",
    "\n",
    "\n",
    "In this lesson, we explore one of the most popular model-based parametric classification methods: **logistic regression**.\n",
    "\n",
    "<img src=\"./figs/parametric_decision.png\" width=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Logistic regression.\n",
    "\n",
    "### 2.1. The logistic function\n",
    "\n",
    "The logistic regression model assumes that the binary class label $Y \\in \\{0,1\\}$ of observation $X\\in \\mathbb{R}^N$ satisfies the expression.\n",
    "\n",
    "$$P_{Y|{\\bf X}}(1|{\\bf x}, {\\bf w}) = g({\\bf w}^\\intercal{\\bf x})$$\n",
    "$$P_{Y|{\\bf,X}}(0|{\\bf x}, {\\bf w}) = 1-g({\\bf w}^\\intercal{\\bf x})$$\n",
    "\n",
    "where ${\\bf w}$ is a parameter vector and $g(·)$ is the *logistic* function, which is defined by\n",
    "\n",
    "$$g(t) = \\frac{1}{1+\\exp(-t)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is straightforward to see that the logistic function has the following properties:\n",
    "\n",
    "- **P1**: Probabilistic output: $\\quad 0 \\le g(t) \\le 1$\n",
    "- **P2**: Symmetry: $\\quad g(-t) = 1-g(t)$\n",
    "- **P3**: Monotonicity: $\\quad g'(t) = g(t)·[1-g(t)] \\ge 0$\n",
    "\n",
    "In the following we define a logistic function in python, and use it to plot a graphical representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise 1**: Verify properties P2 and P3.\n",
    "\n",
    "**Exercise 2**: Implement a function to compute the logistic function, and use it to plot such function in the inverval $[-6,6]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the logistic function\n",
    "def logistic(t):\n",
    "    #<SOL>\n",
    "    #</SOL>\n",
    "\n",
    "# Plot the logistic function\n",
    "t = np.arange(-6, 6, 0.1)\n",
    "z = logistic(t)\n",
    "\n",
    "plt.plot(t, z)\n",
    "plt.xlabel('$t$', fontsize=14)\n",
    "plt.ylabel('$g(t)$', fontsize=14)\n",
    "plt.title('The logistic function')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.2. Classifiers based on the logistic model.\n",
    "\n",
    "The MAP classifier under a logistic model will have the form\n",
    "\n",
    "$$P_{Y|{\\bf X}}(1|{\\bf x}, {\\bf w}) = g({\\bf w}^\\intercal{\\bf x}) \\quad\\mathop{\\gtrless}^{\\hat{y}=1}_{\\hat{y}=0} \\quad \\frac{1}{2} $$\n",
    "\n",
    "Therefore\n",
    "\n",
    "$$\n",
    "2 \\quad\\mathop{\\gtrless}^{\\hat{y}=1}_{\\hat{y}=0} \\quad  \n",
    "1 + \\exp(-{\\bf w}^\\intercal{\\bf x}) $$\n",
    "\n",
    "which is equivalent to\n",
    "\n",
    "$${\\bf w}^\\intercal{\\bf x} \n",
    "\\quad\\mathop{\\gtrless}^{\\hat{y}=1}_{\\hat{y}=0}\\quad \n",
    "0 $$\n",
    "\n",
    "Therefore, the classifiers based on the logistic model are given by linear decision boundaries passing through the origin, ${\\bf x} = {\\bf 0}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Weight vector:\n",
    "w = [4, 8]   # Try different weights\n",
    "\n",
    "# Create a rectangular grid.\n",
    "x_min = -1\n",
    "x_max = 1\n",
    "dx = x_max - x_min\n",
    "h = float(dx) / 200\n",
    "xgrid = np.arange(x_min, x_max, h)\n",
    "xx0, xx1 = np.meshgrid(xgrid, xgrid)\n",
    "\n",
    "# Compute the logistic map for the given weights\n",
    "Z = logistic(w[0]*xx0 + w[1]*xx1)\n",
    "\n",
    "# Plot the logistic map\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(xx0, xx1, Z, cmap=plt.cm.copper)\n",
    "ax.contour(xx0, xx1, Z, levels=[0.5], colors='b', linewidths=(3,))\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$x_1$')\n",
    "ax.set_zlabel('P(1|x,w)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code fragment represents the output of the same classifier, representing the output of the logistic function in the $x_0$-$x_1$ plane, encoding the value of the logistic function in the representation color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS = plt.contourf(xx0, xx1, Z)\n",
    "CS2 = plt.contour(CS, levels=[0.5],\n",
    "                  colors='m', linewidths=(3,))\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$x_1$')\n",
    "\n",
    "plt.colorbar(CS, ticks=[0, 0.5, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.3. Nonlinear classifiers.\n",
    "\n",
    "The logistic model can be extended to construct non-linear classifiers by using non-linear data transformations. A general form for a nonlinear logistic regression model is\n",
    "\n",
    "$$P_{Y|{\\bf X}}(1|{\\bf x}, {\\bf w}) = g[{\\bf w}^\\intercal{\\bf z}({\\bf x})] $$\n",
    "\n",
    "where ${\\bf z}({\\bf x})$ is an arbitrary nonlinear transformation of the original variables. The boundary decision in that case is given by equation\n",
    "\n",
    "$$\n",
    "{\\bf w}^\\intercal{\\bf z} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise 3**: Modify the code above to generate a 3D surface plot of the polynomial logistic regression model given by\n",
    "\n",
    "$$\n",
    "P_{Y|{\\bf X}}(1|{\\bf x}, {\\bf w}) = g(1 + 10 x_0 + 10 x_1 - 20 x_0^2 + 5 x_0 x_1 + x_1^2) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Weight vector:\n",
    "w = [1, 10, 10, -20, 5, 1]   # Try different weights\n",
    "\n",
    "# Create a regtangular grid.\n",
    "x_min = -1\n",
    "x_max = 1\n",
    "dx = x_max - x_min\n",
    "h = float(dx) / 200\n",
    "xgrid = np.arange(x_min, x_max, h)\n",
    "xx0, xx1 = np.meshgrid(xgrid, xgrid)\n",
    "\n",
    "# Compute the logistic map for the given weights\n",
    "# Z = <FILL IN>\n",
    "\n",
    "# Plot the logistic map\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(xx0, xx1, Z, cmap=plt.cm.copper)\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$x_1$')\n",
    "ax.set_zlabel('P(1|x,w)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS = plt.contourf(xx0, xx1, Z)\n",
    "CS2 = plt.contour(CS, levels=[0.5],\n",
    "                  colors='m', linewidths=(3,))\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$x_1$')\n",
    "\n",
    "plt.colorbar(CS, ticks=[0, 0.5, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Inference\n",
    "\n",
    "Remember that the idea of parametric classification is to use the training data set $\\mathcal D = \\{({\\bf x}_k, y_k) \\in {\\mathbb{R}}^N \\times \\{0,1\\}, k=0,\\ldots,{K-1}\\}$ to set the parameter vector ${\\bf w}$ according to certain criterion. Then, the estimate $\\hat{\\bf w}$ can be used to compute the label prediction for any new observation as \n",
    "\n",
    "$$\\hat{y} = \\arg\\max_y P_{Y|{\\bf X}}(y|{\\bf x},\\hat{\\bf w}).$$\n",
    "\n",
    "<img src=\"figs/parametric_decision.png\" width=400>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We need still to choose a criterion to optimize with the selection of the parameter vector. In the notebook, we will discuss two different approaches to the estimation of ${\\bf w}$:\n",
    "\n",
    "   * Maximum Likelihood (ML): $\\hat{\\bf w}_{\\text{ML}} = \\arg\\max_{\\bf w} P_{{\\mathcal D}|{\\bf W}}({\\mathcal D}|{\\bf w})$\n",
    "   * Maximum *A Posteriori* (MAP): $\\hat{\\bf w}_{\\text{MAP}} = \\arg\\max_{\\bf w} p_{{\\bf W}|{\\mathcal D}}({\\bf w}|{\\mathcal D})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "For the mathematical derivation of the logistic regression algorithm, the following representation of the logistic model will be useful: noting that\n",
    "\n",
    "$$P_{Y|{\\bf X}}(0|{\\bf x}, {\\bf w}) = 1-g[{\\bf w}^\\intercal{\\bf z}({\\bf x})]\n",
    "= g[-{\\bf w}^\\intercal{\\bf z}({\\bf x})]$$\n",
    "\n",
    "we can write\n",
    "\n",
    "$$P_{Y|{\\bf X}}(y|{\\bf x}, {\\bf w}) = g[\\overline{y}{\\bf w}^\\intercal{\\bf z}({\\bf x})]$$\n",
    "\n",
    "where $\\overline{y} = 2y-1$ is a *symmetrized label* ($\\overline{y}\\in\\{-1, 1\\}$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1. Model assumptions\n",
    "\n",
    "In the following, we will make the following assumptions:\n",
    "\n",
    "- **A1**. (Logistic Regression): We assume a logistic model for the *a posteriori* probability of ${Y}$ given ${\\bf X}$, i.e.,\n",
    "\n",
    "$$P_{Y|{\\bf X}}(y|{\\bf x}, {\\bf w}) = g\\left({\\bar y}\\cdot {\\bf w}^\\intercal{\\bf z}({\\bf x})\\right).$$\n",
    "\n",
    "- **A2**. All samples in ${\\mathcal D}$ have been generated from the same distribution, $p_{{\\bf X}, Y}({\\bf x}, y)$.\n",
    "\n",
    "- **A3**. Input variables $\\bf x$ do not depend on $\\bf w$. This implies that \n",
    "\n",
    "$$p({\\bf x}|{\\bf w}) = p({\\bf x})$$\n",
    "\n",
    "- **A4**. Targets $y_0, \\cdots, y_{K-1}$ are statistically independent given $\\bf w$ and the inputs ${\\bf x}_0, \\cdots, {\\bf x}_{K-1}$, that is:\n",
    "\n",
    "$$P(y_0, \\cdots, y_{K-1} | {\\bf x}_0, \\cdots, {\\bf x}_{K-1}, {\\bf w}) = \\prod_{k=0}^{K-1} P(y_k | {\\bf x}_k, {\\bf w})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/latex",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2. ML estimation.\n",
    "\n",
    "The ML estimate is defined as\n",
    "\n",
    "$$\\hat{\\bf w}_{\\text{ML}} = \\arg\\max_{\\bf w} P_{{\\mathcal D}|{\\bf W}}({\\mathcal D}|{\\bf w})$$\n",
    "\n",
    "Ussing assumptions A2 and A3 above, we have that\n",
    "\n",
    "\\begin{align}\n",
    "P_{{\\mathcal D}|{\\bf W}}({\\mathcal D}|{\\bf w}) & =  p(y_0, \\cdots, y_{K-1},{\\bf x}_0, \\cdots, {\\bf x}_{K-1}| {\\bf w}) \\\\\n",
    "& =  P(y_0, \\cdots, y_{K-1}|{\\bf x}_0, \\cdots, {\\bf x}_{K-1}, {\\bf w}) \\; p({\\bf x}_0, \\cdots, {\\bf x}_{K-1}| {\\bf w}) \\\\\n",
    "& = P(y_0, \\cdots, y_{K-1}|{\\bf x}_0, \\cdots, {\\bf x}_{K-1}, {\\bf w}) \\; p({\\bf x}_0, \\cdots, {\\bf x}_{K-1})\\end{align}\n",
    "\n",
    "Finally, using assumption A4, we can formulate the ML estimation of $\\bf w$ as the resolution of the following optimization problem\n",
    "\n",
    "\\begin{align}\n",
    "\\hat {\\bf w}_\\text{ML} & = \\arg \\max_{\\bf w} P(y_0, \\cdots, y_{K-1}|{\\bf x}_0, \\cdots, {\\bf x}_{K-1}, {\\bf w}) \\\\\n",
    "& = \\arg \\max_{\\bf w} \\prod_{k=0}^{K-1} P(y_k|{\\bf x}_k, {\\bf w}) \\\\\n",
    "& = \\arg \\max_{\\bf w} \\sum_{k=0}^{K-1} \\log P(y_k|{\\bf x}_k, {\\bf w}) \\\\\n",
    "& = \\arg \\min_{\\bf w} \\sum_{k=0}^{K-1} - \\log P(y_k|{\\bf x}_k, {\\bf w})\n",
    "\\end{align}\n",
    "\n",
    "where the arguments of the maximization or minimization problems of the last three lines are usually referred to as the **likelihood**, **log-likelihood** $\\left[L(\\bf w)\\right]$, and **negative log-likelihood** $\\left[\\text{NLL}(\\bf w)\\right]$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/latex",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Now, using A1 (the logistic model)\n",
    "\n",
    "\\begin{align}\n",
    "\\text{NLL}({\\bf w}) \n",
    "    &= - \\sum_{k=0}^{K-1}\\log\\left[g\\left(\\overline{y}_k{\\bf w}^\\intercal {\\bf z}_k\\right)\\right]   \\\\\n",
    "    &= \\sum_{k=0}^{K-1}\\log\\left[1+\\exp\\left(-\\overline{y}_k{\\bf w}^\\intercal {\\bf z}_k\\right)\\right]\n",
    "\\end{align}\n",
    "\n",
    "where ${\\bf z}_k={\\bf z}({\\bf x}_k)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/latex",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "It can be shown that $\\text{NLL}({\\bf w})$ is a convex and differentiable function of ${\\bf w}$. Therefore, its minimum is a point with zero gradient.\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_{\\bf w} \\text{NLL}(\\hat{\\bf w}_{\\text{ML}}) \n",
    "    &= - \\sum_{k=0}^{K-1} \n",
    "       \\frac{\\exp\\left(-\\overline{y}_k\\hat{\\bf w}_{\\text{ML}}^\\intercal {\\bf z}_k\\right) \\overline{y}_k {\\bf z}_k}\n",
    "       {1+\\exp\\left(-\\overline{y}_k\\hat{\\bf w}_{\\text{ML}}^\\intercal {\\bf z}_k\n",
    "       \\right)} = \\\\\n",
    "    &= - \\sum_{k=0}^{K-1} \\left[y_k-g(\\hat{\\bf w}_{\\text{ML}}^T {\\bf z}_k)\\right] {\\bf z}_k = 0\n",
    "\\end{align}\n",
    "\n",
    "Unfortunately, $\\hat{\\bf w}_{\\text{ML}}$ cannot be taken out from the above equation, and some iterative optimization algorithm must be used to search for the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2. Gradient descent.\n",
    "\n",
    "A simple iterative optimization algorithm is <a href = https://en.wikipedia.org/wiki/Gradient_descent> gradient descent</a>. \n",
    "\n",
    "\\begin{align}\n",
    "{\\bf w}_{n+1} = {\\bf w}_n - \\rho_n \\nabla_{\\bf w} \\text{NLL}({\\bf w}_n)\n",
    "\\end{align}\n",
    "\n",
    "where $\\rho_n >0$ is the *learning step*.\n",
    "\n",
    "Applying the gradient descent rule to logistic regression, we get the following algorithm:\n",
    "\n",
    "\\begin{align}\n",
    "{\\bf w}_{n+1} &= {\\bf w}_n \n",
    "    + \\rho_n \\sum_{k=0}^{K-1} \\left[y_k-g({\\bf w}_n^\\intercal {\\bf z}_k)\\right] {\\bf z}_k\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Defining vectors\n",
    "\n",
    "\\begin{align}\n",
    "{\\bf y} &= [y_0,\\ldots,y_{K-1}]^\\top \\\\\n",
    "\\hat{\\bf p}_n &= [g({\\bf w}_n^\\top {\\bf z}_0), \\ldots, g({\\bf w}_n^\\top {\\bf z}_{K-1})]^\\top\n",
    "\\end{align}\n",
    "and matrix\n",
    "\\begin{align}\n",
    "{\\bf Z} = \\left[{\\bf z}_0,\\ldots,{\\bf z}_{K-1}\\right]^\\top\n",
    "\\end{align}\n",
    "\n",
    "we can write\n",
    "\n",
    "\\begin{align}\n",
    "{\\bf w}_{n+1} &= {\\bf w}_n \n",
    "    + \\rho_n {\\bf Z}^\\top \\left({\\bf y}-\\hat{\\bf p}_n\\right)\n",
    "\\end{align}\n",
    "\n",
    "In the following, we will explore the behavior of the gradient descend method using the Iris Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.2.1 Example: Iris Dataset.\n",
    "\n",
    "As an illustration, consider the <a href = http://archive.ics.uci.edu/ml/datasets/Iris> Iris dataset </a>, taken from the <a href=http://archive.ics.uci.edu/ml/> UCI Machine Learning repository</a>. This data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant (*setosa*, *versicolor* or *virginica*). Each instance contains 4 measurements of given flowers: sepal length, sepal width, petal length and petal width, all in centimeters. \n",
    "\n",
    "We will try to fit the logistic regression model to discriminate between two classes using only two attributes.\n",
    "\n",
    "First, we load the dataset and split them in training and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Adapted from a notebook by Jason Brownlee\n",
    "def loadDataset(filename, split):\n",
    "    xTrain = []\n",
    "    cTrain = []\n",
    "    xTest = []\n",
    "    cTest = []\n",
    "\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "    for i in range(len(dataset)-1):\n",
    "        for y in range(4):\n",
    "            dataset[i][y] = float(dataset[i][y])\n",
    "        item = dataset[i]\n",
    "        if random.random() < split:\n",
    "            xTrain.append(item[0:4])\n",
    "            cTrain.append(item[4])\n",
    "        else:\n",
    "            xTest.append(item[0:4])\n",
    "            cTest.append(item[4])\n",
    "    return xTrain, cTrain, xTest, cTest\n",
    "\n",
    "xTrain_all, cTrain_all, xTest_all, cTest_all = loadDataset('iris.data', 0.66)\n",
    "nTrain_all = len(xTrain_all)\n",
    "nTest_all = len(xTest_all)\n",
    "print('Train:', nTrain_all)\n",
    "print('Test:', nTest_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we select two classes and two attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Select attributes\n",
    "i = 0 # Try 0,1,2,3\n",
    "j = 1 # Try 0,1,2,3 with j!=i\n",
    "\n",
    "# Select two classes\n",
    "c0 = 'Iris-versicolor' \n",
    "c1 = 'Iris-virginica'\n",
    "\n",
    "# Select two coordinates\n",
    "ind = [i, j]\n",
    "\n",
    "# Take training test\n",
    "X_tr = np.array([[xTrain_all[n][i] for i in ind] for n in range(nTrain_all) \n",
    "                  if cTrain_all[n]==c0 or cTrain_all[n]==c1])\n",
    "C_tr = [cTrain_all[n] for n in range(nTrain_all) \n",
    "          if cTrain_all[n]==c0 or cTrain_all[n]==c1]\n",
    "Y_tr = np.array([int(c==c1) for c in C_tr])\n",
    "n_tr = len(X_tr)\n",
    "\n",
    "# Take test set\n",
    "X_tst = np.array([[xTest_all[n][i] for i in ind] for n in range(nTest_all) \n",
    "                 if cTest_all[n]==c0 or cTest_all[n]==c1])\n",
    "C_tst = [cTest_all[n] for n in range(nTest_all) \n",
    "         if cTest_all[n]==c0 or cTest_all[n]==c1]\n",
    "Y_tst = np.array([int(c==c1) for c in C_tst])\n",
    "n_tst = len(X_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 3.2.2. Data normalization\n",
    "\n",
    "Normalization of data is a common pre-processing step in many machine learning algorithms. Its goal is to get a dataset where all input coordinates have a similar scale. Learning algorithms usually show less instabilities and convergence problems when data are normalized.\n",
    "\n",
    "We will define a normalization function that returns a training data matrix with zero sample mean and unit sample variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(X, mx=None, sx=None):\n",
    "    \n",
    "    # Compute means and standard deviations\n",
    "    if mx is None:\n",
    "        mx = np.mean(X, axis=0)\n",
    "    if sx is None:\n",
    "        sx = np.std(X, axis=0)\n",
    "\n",
    "    # Normalize\n",
    "    X0 = (X-mx)/sx\n",
    "\n",
    "    return X0, mx, sx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we can normalize training and test data. Observe in the code that the same transformation should be applied to training and test data. This is the reason why normalization with the test data is done using the means and the variances computed with the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "Xn_tr, mx, sx = normalize(X_tr)\n",
    "Xn_tst, mx, sx = normalize(X_tst, mx, sx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following figure generates a plot of the normalized training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Separate components of x into different arrays (just for the plots)\n",
    "x0c0 = [Xn_tr[n][0] for n in range(n_tr) if Y_tr[n]==0]\n",
    "x1c0 = [Xn_tr[n][1] for n in range(n_tr) if Y_tr[n]==0]\n",
    "x0c1 = [Xn_tr[n][0] for n in range(n_tr) if Y_tr[n]==1]\n",
    "x1c1 = [Xn_tr[n][1] for n in range(n_tr) if Y_tr[n]==1]\n",
    "\n",
    "# Scatterplot.\n",
    "labels = {'Iris-setosa': 'Setosa', \n",
    "          'Iris-versicolor': 'Versicolor',\n",
    "          'Iris-virginica': 'Virginica'}\n",
    "plt.plot(x0c0, x1c0,'r.', label=labels[c0])\n",
    "plt.plot(x0c1, x1c1,'g+', label=labels[c1])\n",
    "plt.xlabel('$x_' + str(ind[0]) + '$')\n",
    "plt.ylabel('$x_' + str(ind[1]) + '$')\n",
    "plt.legend(loc='best')\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order to apply the gradient descent rule, we need to define two methods: \n",
    " - A `fit` method, that receives the training data and returns the model weights and the value of the negative log-likelihood during all iterations.\n",
    " - A `predict` method, that receives the model weight and a set of inputs, and returns the posterior class probabilities for that input, as well as their corresponding class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def logregFit(Z_tr, Y_tr, rho, n_it):\n",
    "\n",
    "    # Data dimension\n",
    "    n_dim = Z_tr.shape[1]\n",
    "\n",
    "    # Initialize variables\n",
    "    nll_tr = np.zeros(n_it)\n",
    "    pe_tr = np.zeros(n_it)\n",
    "    Y_tr2 = 2*Y_tr - 1     # Transform labels into binary symmetric.\n",
    "    w = np.random.randn(n_dim,1)\n",
    "\n",
    "    # Running the gradient descent algorithm\n",
    "    for n in range(n_it):\n",
    "        \n",
    "        # Compute posterior probabilities for weight w\n",
    "        p1_tr = logistic(np.dot(Z_tr, w))\n",
    "\n",
    "        # Compute negative log-likelihood\n",
    "        # (note that this is not required for the weight update, only for nll tracking)\n",
    "        nll_tr[n] = np.sum(np.log(1 + np.exp(-np.dot(Y_tr2*Z_tr, w)))) \n",
    "\n",
    "        # Update weights\n",
    "        w += rho*np.dot(Z_tr.T, Y_tr - p1_tr)\n",
    "    \n",
    "    return w, nll_tr\n",
    "\n",
    "def logregPredict(Z, w):\n",
    "\n",
    "    # Compute posterior probability of class 1 for weights w.\n",
    "    p = logistic(np.dot(Z, w)).flatten()\n",
    "    \n",
    "    # Class\n",
    "    D = [int(round(pn)) for pn in p]\n",
    "    \n",
    "    return p, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can test the behavior of the gradient descent method by fitting a logistic regression model with ${\\bf z}({\\bf x}) = (1, {\\bf x}^\\top)^\\top$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters of the algorithms\n",
    "rho = float(1)/50    # Learning step\n",
    "n_it = 200   # Number of iterations\n",
    "\n",
    "# Compute Z's\n",
    "Z_tr = np.c_[np.ones(n_tr), Xn_tr] \n",
    "Z_tst = np.c_[np.ones(n_tst), Xn_tst]\n",
    "n_dim = Z_tr.shape[1]\n",
    "\n",
    "# Convert target arrays to column vectors\n",
    "Y_tr2 = Y_tr[np.newaxis].T\n",
    "Y_tst2 = Y_tst[np.newaxis].T\n",
    "\n",
    "# Running the gradient descent algorithm\n",
    "w, nll_tr = logregFit(Z_tr, Y_tr2, rho, n_it)\n",
    "\n",
    "# Classify training and test data\n",
    "p_tr, D_tr = logregPredict(Z_tr, w)\n",
    "p_tst, D_tst = logregPredict(Z_tst, w)\n",
    "\n",
    "# Compute error rates\n",
    "E_tr = D_tr!=Y_tr\n",
    "E_tst = D_tst!=Y_tst\n",
    "\n",
    "# Error rates\n",
    "pe_tr = float(sum(E_tr)) / n_tr\n",
    "pe_tst = float(sum(E_tst)) / n_tst\n",
    "\n",
    "# NLL plot.\n",
    "plt.plot(range(n_it), nll_tr,'b.:', label='Train')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Negative Log-Likelihood')\n",
    "plt.legend()\n",
    "\n",
    "print('The optimal weights are:')\n",
    "print(w)\n",
    "print('The final error rates are:')\n",
    "print('- Training:', pe_tr)\n",
    "print('- Test:', pe_tst)\n",
    "print('The NLL after training is', nll_tr[len(nll_tr)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.2.3. Free parameters\n",
    "\n",
    "Under certain conditions, the gradient descent method can be shown to converge asymptotically (i.e. as the number of iterations goes to infinity) to the ML estimate of the logistic model. However, in practice, the final estimate of the weights ${\\bf w}$ depend on several factors:\n",
    "\n",
    "- Number of iterations\n",
    "- Initialization\n",
    "- Learning step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise 4**: Visualize the variability of gradient descent caused by initializations. To do so, fix the number of iterations to 200 and the learning step, and execute the gradient descent 100 times, storing the training error rate of each execution. Plot the histogram of the error rate values.\n",
    "\n",
    "Note that you can do this exercise with a loop over the 100 executions, including the code in the previous code slide inside the loop, with some proper modifications. To plot a histogram of the values in array `p` with `n`bins, you can use `plt.hist(p, n)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### 3.2.3.1. Learning step\n",
    "\n",
    "The learning step, $\\rho$, is a free parameter of the algorithm. Its choice is critical for the convergence of the algorithm. Too large values of $\\rho$ make the algorithm diverge. For too small values, the convergence gets very slow and more iterations are required for a good convergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise 5**: Observe the evolution of the negative log-likelihood with the number of iterations for different values of $\\rho$. It is easy to check that, for large enough $\\rho$, the gradient descent method does not converge. Can you estimate (through manual observation) an approximate value of $\\rho$ stating a boundary between convergence and divergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise 6**: In this exercise we explore the influence of the learning step more sistematically. Use the code in the previouse exercises to compute, for every value of $\\rho$, the average error rate over 100 executions. Plot the average error rate vs. $\\rho$. \n",
    "\n",
    "Note that you should explore the values of $\\rho$ in a logarithmic scale. For instance, you can take $\\rho = 1, \\frac{1}{10}, \\frac{1}{100}, \\frac{1}{1000}, \\ldots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In practice, the selection of $\\rho$ may be a matter of trial an error. Also there is some theoretical evidence that the learning step should decrease along time up to cero, and the sequence $\\rho_n$ should satisfy two conditions:\n",
    "- C1: $\\sum_{n=0}^{\\infty} \\rho_n^2 < \\infty$ (decrease slowly)\n",
    "- C2: $\\sum_{n=0}^{\\infty} \\rho_n = \\infty$ (but not too slowly)\n",
    "\n",
    "For instance, we can take $\\rho_n= \\frac{1}{n}$. Another common choice is $\\rho_n = \\frac{\\alpha}{1+\\beta n}$ where $\\alpha$ and $\\beta$ are also free parameters that can be selected by trial and error with some heuristic method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.2.4. Visualizing the posterior map.\n",
    "\n",
    "We can also visualize the posterior probability map estimated by the logistic regression model for the estimated weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a regtangular grid.\n",
    "x_min, x_max = Xn_tr[:, 0].min(), Xn_tr[:, 0].max() \n",
    "y_min, y_max = Xn_tr[:, 1].min(), Xn_tr[:, 1].max()\n",
    "dx = x_max - x_min\n",
    "dy = y_max - y_min\n",
    "h = dy /400\n",
    "xx, yy = np.meshgrid(np.arange(x_min - 0.1 * dx, x_max + 0.1 * dx, h),\n",
    "                     np.arange(y_min - 0.1 * dx, y_max + 0.1 * dy, h))\n",
    "X_grid = np.array([xx.ravel(), yy.ravel()]).T\n",
    "\n",
    "# Compute Z's\n",
    "Z_grid = np.c_[np.ones(X_grid.shape[0]), X_grid] \n",
    "\n",
    "# Compute the classifier output for all samples in the grid.\n",
    "pp, dd = logregPredict(Z_grid, w)\n",
    "\n",
    "# Paint output maps\n",
    "pylab.rcParams['figure.figsize'] = 6, 6  # Set figure size\n",
    "\n",
    "# Put the result into a color plot\n",
    "plt.plot(x0c0, x1c0,'r.', label=labels[c0])\n",
    "plt.plot(x0c1, x1c1,'g+', label=labels[c1])\n",
    "plt.xlabel('$x_' + str(ind[0]) + '$')\n",
    "plt.ylabel('$x_' + str(ind[1]) + '$')\n",
    "plt.legend(loc='best')\n",
    "plt.axis('equal')\n",
    "pp = pp.reshape(xx.shape)\n",
    "CS = plt.contourf(xx, yy, pp, cmap=plt.cm.copper)\n",
    "plt.contour(xx, yy, pp, levels=[0.5],\n",
    "                  colors='b', linewidths=(3,))\n",
    "\n",
    "plt.colorbar(CS, ticks=[0, 0.5, 1])\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.2.5. Polynomial Logistic Regression\n",
    "\n",
    "The error rates of the logistic regression model can be potentially reduced by using polynomial transformations.\n",
    "\n",
    "To compute the polynomial transformation up to a given degree, we can use the `PolynomialFeatures` method in `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters of the algorithms\n",
    "rho = float(1)/50    # Learning step\n",
    "n_it = 500   # Number of iterations\n",
    "g = 5 # Degree of polynomial\n",
    "\n",
    "# Compute Z_tr\n",
    "poly = PolynomialFeatures(degree=g)\n",
    "Z_tr = poly.fit_transform(Xn_tr)\n",
    "# Normalize columns (this is useful to make algorithms more stable).)\n",
    "Zn, mz, sz = normalize(Z_tr[:,1:])\n",
    "Z_tr = np.concatenate((np.ones((n_tr,1)), Zn), axis=1)\n",
    "\n",
    "# Compute Z_tst\n",
    "Z_tst = poly.fit_transform(Xn_tst)\n",
    "Zn, mz, sz = normalize(Z_tst[:,1:], mz, sz)\n",
    "Z_tst = np.concatenate((np.ones((n_tst,1)), Zn), axis=1)\n",
    "\n",
    "# Convert target arrays to column vectors\n",
    "Y_tr2 = Y_tr[np.newaxis].T\n",
    "Y_tst2 = Y_tst[np.newaxis].T\n",
    "\n",
    "# Running the gradient descent algorithm\n",
    "w, nll_tr = logregFit(Z_tr, Y_tr2, rho, n_it)\n",
    "\n",
    "# Classify training and test data\n",
    "p_tr, D_tr = logregPredict(Z_tr, w)\n",
    "p_tst, D_tst = logregPredict(Z_tst, w)\n",
    "    \n",
    "# Compute error rates\n",
    "E_tr = D_tr!=Y_tr\n",
    "E_tst = D_tst!=Y_tst\n",
    "\n",
    "# Error rates\n",
    "pe_tr = float(sum(E_tr)) / n_tr\n",
    "pe_tst = float(sum(E_tst)) / n_tst\n",
    "\n",
    "# NLL plot.\n",
    "plt.plot(range(n_it), nll_tr,'b.:', label='Train')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Negative Log-Likelihood')\n",
    "plt.legend()\n",
    "\n",
    "print('The optimal weights are:')\n",
    "print(w)\n",
    "print('The final error rates are:')\n",
    "print('- Training:', pe_tr)\n",
    "print('- Test:', pe_tst)\n",
    "print('The NLL after training is', nll_tr[len(nll_tr)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Visualizing the posterior map we can se that the polynomial transformation produces nonlinear decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Compute Z_grid\n",
    "Z_grid = poly.fit_transform(X_grid)\n",
    "n_grid = Z_grid.shape[0]\n",
    "Zn, mz, sz = normalize(Z_grid[:,1:], mz, sz)\n",
    "Z_grid = np.concatenate((np.ones((n_grid,1)), Zn), axis=1)\n",
    "\n",
    "# Compute the classifier output for all samples in the grid.\n",
    "pp, dd = logregPredict(Z_grid, w)\n",
    "pp = pp.reshape(xx.shape)\n",
    "\n",
    "# Paint output maps\n",
    "pylab.rcParams['figure.figsize'] = 6, 6  # Set figure size\n",
    "\n",
    "plt.plot(x0c0, x1c0,'r.', label=labels[c0])\n",
    "plt.plot(x0c1, x1c1,'g+', label=labels[c1])\n",
    "plt.xlabel('$x_' + str(ind[0]) + '$')\n",
    "plt.ylabel('$x_' + str(ind[1]) + '$')\n",
    "plt.axis('equal')\n",
    "plt.legend(loc='best')\n",
    "CS = plt.contourf(xx, yy, pp, cmap=plt.cm.copper)\n",
    "plt.contour(xx, yy, pp, levels=[0.5],\n",
    "                  colors='b', linewidths=(3,))\n",
    "\n",
    "plt.colorbar(CS, ticks=[0, 0.5, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Regularization and MAP estimation.\n",
    "\n",
    "An alternative to the ML estimation of the weights in logistic regression is Maximum A Posteriori estimation. Modelling the logistic regression weights as a random variable with prior distribution $p_{\\bf W}({\\bf w})$, the MAP estimate is defined as\n",
    "\n",
    "$$\n",
    "\\hat{\\bf w}_{\\text{MAP}} = \\arg\\max_{\\bf w} p({\\bf w}|{\\mathcal D})\n",
    "$$\n",
    "\n",
    "The posterior density $p({\\bf w}|{\\mathcal D})$ is related to the likelihood function and the prior density of the weights, $p_{\\bf W}({\\bf w})$ through the Bayes rule\n",
    "\n",
    "$$\n",
    "p({\\bf w}|{\\mathcal D}) = \n",
    "    \\frac{P\\left({\\mathcal D}|{\\bf w}\\right) \\; p_{\\bf W}({\\bf w})}\n",
    "         {p\\left({\\mathcal D}\\right)}\n",
    "$$\n",
    "\n",
    "In general, the denominator in this expression cannot be computed analytically. However, it is not required for MAP estimation because it does not depend on ${\\bf w}$. Therefore, the MAP solution is given by\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\bf w}_{\\text{MAP}} & = \\arg\\max_{\\bf w} \\left\\{ P\\left({\\mathcal D}|{\\bf w}\\right) \\; p_{\\bf W}({\\bf w}) \\right\\}\\\\\n",
    "& = \\arg\\max_{\\bf w} \\left\\{ L({\\mathbf w}) + \\log p_{\\bf W}({\\bf w})\\right\\} \\\\\n",
    "& = \\arg\\min_{\\bf w} \\left\\{ \\text{NLL}({\\mathbf w}) - \\log p_{\\bf W}({\\bf w})\\right\\}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "In the light of this expression, we can conclude that the MAP solution is affected by two terms:\n",
    "\n",
    "   - The likelihood, which takes large values for parameter vectors $\\bf w$ that fit well the training data (smaller $\\text{NLL}$ values)\n",
    "   - The prior distribution of weights $p_{\\bf W}({\\bf w})$, which expresses our *a priori* preference for some solutions. **Usually, we recur to prior distributions that take large values when $\\|{\\bf w}\\|$ is small (associated to smooth classification borders).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can check that the MAP criterion adds a penalty term to the ML objective, that penalizes parameter vectors for which the prior distribution of weights takes small values.\n",
    "\n",
    "### 4.1 MAP estimation with Gaussian prior\n",
    "\n",
    "If we assume that ${\\bf W}$ follows a zero-mean Gaussian random variable with variance matrix $v{\\bf I}$, \n",
    "\n",
    "$$\n",
    "p_{\\bf W}({\\bf w}) = \\frac{1}{(2\\pi v)^{N/2}} \\exp\\left(-\\frac{1}{2v}\\|{\\bf w}\\|^2\\right)\n",
    "$$\n",
    "\n",
    "the MAP estimate becomes\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\bf w}_{\\text{MAP}} \n",
    "  &= \\arg\\min_{\\bf w} \\left\\{\\text{NLL}({\\bf w}) + \\frac{1}{C}\\|{\\bf w}\\|^2\n",
    "         \\right\\}\n",
    "\\end{align}\n",
    "\n",
    "where $C = 2v$. Noting that\n",
    "\n",
    "$$\\nabla_{\\bf w}\\left\\{\\text{NLL}({\\bf w}) + \\frac{1}{C}\\|{\\bf w}\\|^2\\right\\} \n",
    "= - {\\bf Z} \\left({\\bf y}-\\hat{\\bf p}_n\\right) + \\frac{2}{C}{\\bf w},\n",
    "$$\n",
    "\n",
    "we obtain the following gradient descent rule for MAP estimation\n",
    "\n",
    "\\begin{align}\n",
    "{\\bf w}_{n+1} &= \\left(1-\\frac{2\\rho_n}{C}\\right){\\bf w}_n \n",
    "    + \\rho_n {\\bf Z} \\left({\\bf y}-\\hat{\\bf p}_n\\right)\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.2 MAP estimation with Laplacian prior\n",
    "\n",
    "If we assume that ${\\bf W}$ follows a multivariate zero-mean Laplacian distribution given by\n",
    "\n",
    "$$\n",
    "p_{\\bf W}({\\bf w}) = \\frac{1}{(2 C)^{N}} \\exp\\left(-\\frac{1}{C}\\|{\\bf w}\\|_1\\right)\n",
    "$$\n",
    "\n",
    "(where $\\|{\\bf w}\\|=|w_1|+\\ldots+|w_N|$ is the $L_1$ norm of ${\\bf w}$), the MAP estimate becomes\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\bf w}_{\\text{MAP}} \n",
    "  &= \\arg\\min_{\\bf w} \\left\\{\\text{NLL}({\\bf w}) + \\frac{1}{C}\\|{\\bf w}\\|_1\n",
    "         \\right\\}\n",
    "\\end{align}\n",
    "\n",
    "The additional term introduced by the prior in the optimization algorithm is usually named the *regularization term*. It is usually very effective to avoid overfitting when the dimension of the weight vectors is high. Parameter $C$ is named the *inverse regularization strength*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Exercise 7**: Derive the gradient descent rules for MAP estimation of the logistic regression weights with Laplacian prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Other optimization algorithms\n",
    "\n",
    "### 5.1. Stochastic Gradient descent.\n",
    "\n",
    "Stochastic gradient descent (SGD) is based on the idea of using a single sample at each iteration of the learning algorithm. The SGD rule for ML logistic regression is\n",
    "\n",
    "\\begin{align}\n",
    "{\\bf w}_{n+1} &= {\\bf w}_n \n",
    "    + \\rho_n {\\bf z}_n \\left(y_n-\\hat{p}_n\\right)\n",
    "\\end{align}\n",
    "\n",
    "Once all samples in the training set have been applied, the algorith can continue by applying the training set several times.\n",
    "\n",
    "The computational cost of each iteration of SGD is much smaller than that of gradient descent, though it usually needs many more iterations to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise 8**: Modify logregFit to implement an algorithm that applies the SGD rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.2. Newton's method\n",
    "\n",
    "Assume that the function to be minimized, $C({\\bf w})$, can be approximated by its second order Taylor series expansion around ${\\bf w}_0$\n",
    "\n",
    "$$ \n",
    "C({\\bf w}) \\approx C({\\bf w}_0) \n",
    "+ \\nabla_{\\bf w}^\\top C({\\bf w}_0)({\\bf w}-{\\bf w}_0)\n",
    "+ \\frac{1}{2}({\\bf w}-{\\bf w}_0)^\\top{\\bf H}({\\bf w}_0)({\\bf w}-{\\bf w}_0)\n",
    "$$\n",
    "\n",
    "where ${\\bf H}({\\bf w})$ is the <a href=https://en.wikipedia.org/wiki/Hessian_matrix> *Hessian* matrix</a> of $C$ at ${\\bf w}$. Taking the gradient of $C({\\bf w})$, and setting the result to ${\\bf 0}$, the minimum of C around ${\\bf w}_0$ can be approximated as\n",
    "\n",
    "$$ \n",
    "{\\bf w}^* = {\\bf w}_0 - {\\bf H}({\\bf w}_0)^{-1} \\nabla_{\\bf w}^\\top C({\\bf w}_0)\n",
    "$$\n",
    "\n",
    "Since the second order polynomial is only an approximation to $C$, ${\\bf w}^*$ is only an approximation to the optimal weight vector, but we can expect ${\\bf w}^*$ to be closer to the minimizer of $C$ than ${\\bf w}_0$. Thus, we can repeat the process, computing a second order approximation around ${\\bf w}^*$ and a new approximation to the minimizer.\n",
    "\n",
    "<a href=https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization> Newton's method</a> is based on this idea. At each optization step, the function to be minimized is approximated by a second order approximation using a Taylor series expansion around the current estimate. As a result, the learning rule becomes\n",
    "\n",
    "$$\\hat{\\bf w}_{n+1} = \\hat{\\bf w}_{n} - \\rho_n {\\bf H}({\\bf w}_n)^{-1} \\nabla_{{\\bf w}}C({\\bf w}_n)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "For instance, for the MAP estimate with Gaussian prior, the *Hessian* matrix becomes\n",
    "\n",
    "$$\n",
    "{\\bf H}({\\bf w}) \n",
    "  = \\frac{2}{C}{\\bf I} \n",
    "  + \\sum_{k=0}^{K-1} g({\\bf w}^\\top {\\bf z}_k) \n",
    "                     \\left[1-g({\\bf w}^\\top {\\bf z}_k)\\right]{\\bf z}_k {\\bf z}_k^\\top\n",
    "$$\n",
    "\n",
    "Defining diagonal matrix\n",
    "\n",
    "$$\n",
    "{\\mathbf S}({\\bf w}) = \\text{diag}\\left[g({\\bf w}^\\top {\\bf z}_k) \\left(1-g({\\bf w}^\\top {\\bf z}_k)\\right)\\right]\n",
    "$$\n",
    "\n",
    "the Hessian matrix can be written in more compact form as\n",
    "\n",
    "$$\n",
    "{\\bf H}({\\bf w}) \n",
    "  = \\frac{2}{C}{\\bf I} + {\\bf Z}^\\top {\\bf S}({\\bf w}) {\\bf Z}\n",
    "$$\n",
    "\n",
    "Therefore, the Newton's algorithm for logistic regression becomes\n",
    "\n",
    "\\begin{align}\n",
    "{\\bf w}_{n+1} = {\\bf w}_{n} + \n",
    "\\rho_n \n",
    "\\left(\\frac{2}{C}{\\bf I} + {\\bf Z}^\\top {\\bf S}({\\bf w}_{n})\n",
    "{\\bf Z}\n",
    "\\right)^{-1} \n",
    "{\\bf Z}^\\top \\left({\\bf y}-\\hat{\\bf p}_n\\right)\n",
    "\\end{align}\n",
    "\n",
    "Some variants of the Newton method are implemented in the <a href=\"http://scikit-learn.org/stable/\"> Scikit-learn </a> package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def logregFit2(Z_tr, Y_tr, rho, n_it, C=1e4):\n",
    "\n",
    "    # Compute Z's\n",
    "    r = 2.0/C\n",
    "    n_dim = Z_tr.shape[1]\n",
    "\n",
    "    # Initialize variables\n",
    "    nll_tr = np.zeros(n_it)\n",
    "    pe_tr = np.zeros(n_it)\n",
    "    w = np.random.randn(n_dim,1)\n",
    "\n",
    "    # Running the gradient descent algorithm\n",
    "    for n in range(n_it):\n",
    "        p_tr = logistic(np.dot(Z_tr, w))\n",
    "        \n",
    "        sk = np.multiply(p_tr, 1-p_tr)\n",
    "        S = np.diag(np.ravel(sk.T))\n",
    "\n",
    "        # Compute negative log-likelihood\n",
    "        nll_tr[n] = - np.dot(Y_tr.T, np.log(p_tr)) - np.dot((1-Y_tr).T, np.log(1-p_tr))\n",
    "\n",
    "        # Update weights\n",
    "        invH = np.linalg.inv(r*np.identity(n_dim) + np.dot(Z_tr.T, np.dot(S, Z_tr)))\n",
    "\n",
    "        w += rho*np.dot(invH, np.dot(Z_tr.T, Y_tr - p_tr))\n",
    "\n",
    "    return w, nll_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the algorithms\n",
    "rho = float(1)/50    # Learning step\n",
    "n_it = 500   # Number of iterations\n",
    "C = 1000\n",
    "g = 4\n",
    "\n",
    "# Compute Z_tr\n",
    "poly = PolynomialFeatures(degree=g)\n",
    "Z_tr = poly.fit_transform(X_tr)\n",
    "# Normalize columns (this is useful to make algorithms more stable).)\n",
    "Zn, mz, sz = normalize(Z_tr[:,1:])\n",
    "Z_tr = np.concatenate((np.ones((n_tr,1)), Zn), axis=1)\n",
    "\n",
    "# Compute Z_tst\n",
    "Z_tst = poly.fit_transform(X_tst)\n",
    "Zn, mz, sz = normalize(Z_tst[:,1:], mz, sz)\n",
    "Z_tst = np.concatenate((np.ones((n_tst,1)), Zn), axis=1)\n",
    "\n",
    "# Convert target arrays to column vectors\n",
    "Y_tr2 = Y_tr[np.newaxis].T\n",
    "Y_tst2 = Y_tst[np.newaxis].T\n",
    "\n",
    "# Running the gradient descent algorithm\n",
    "w, nll_tr = logregFit2(Z_tr, Y_tr2, rho, n_it, C)\n",
    "\n",
    "# Classify training and test data\n",
    "p_tr, D_tr = logregPredict(Z_tr, w)\n",
    "p_tst, D_tst = logregPredict(Z_tst, w)\n",
    "    \n",
    "# Compute error rates\n",
    "E_tr = D_tr!=Y_tr\n",
    "E_tst = D_tst!=Y_tst\n",
    "\n",
    "# Error rates\n",
    "pe_tr = float(sum(E_tr)) / n_tr\n",
    "pe_tst = float(sum(E_tst)) / n_tst\n",
    "\n",
    "# NLL plot.\n",
    "plt.plot(range(n_it), nll_tr,'b.:', label='Train')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Negative Log-Likelihood')\n",
    "plt.legend()\n",
    "\n",
    "print('The final error rates are:')\n",
    "print('- Training:', str(pe_tr))\n",
    "print('- Test:', str(pe_tst))\n",
    "print('The NLL after training is:', str(nll_tr[len(nll_tr)-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6. Logistic regression in Scikit Learn.\n",
    "\n",
    "The <a href=\"http://scikit-learn.org/stable/\"> scikit-learn </a> package includes an efficient implementation of <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\"> logistic regression</a>. To use it, we must first create a classifier object, specifying the parameters of the logistic regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression object.\n",
    "LogReg = linear_model.LogisticRegression(C=1.0)\n",
    "\n",
    "# Compute Z_tr\n",
    "poly = PolynomialFeatures(degree=g)\n",
    "Z_tr = poly.fit_transform(Xn_tr)\n",
    "# Normalize columns (this is useful to make algorithms more stable).)\n",
    "Zn, mz, sz = normalize(Z_tr[:,1:])\n",
    "Z_tr = np.concatenate((np.ones((n_tr,1)), Zn), axis=1)\n",
    "\n",
    "# Compute Z_tst\n",
    "Z_tst = poly.fit_transform(Xn_tst)\n",
    "Zn, mz, sz = normalize(Z_tst[:,1:], mz, sz)\n",
    "Z_tst = np.concatenate((np.ones((n_tst,1)), Zn), axis=1)\n",
    "\n",
    "# Fit model to data.\n",
    "LogReg.fit(Z_tr, Y_tr)\n",
    "\n",
    "# Classify training and test data\n",
    "D_tr = LogReg.predict(Z_tr)\n",
    "D_tst = LogReg.predict(Z_tst)\n",
    "    \n",
    "# Compute error rates\n",
    "E_tr = D_tr!=Y_tr\n",
    "E_tst = D_tst!=Y_tst\n",
    "\n",
    "# Error rates\n",
    "pe_tr = float(sum(E_tr)) / n_tr\n",
    "pe_tst = float(sum(E_tst)) / n_tst\n",
    "\n",
    "print('The final error rates are:')\n",
    "print('- Training:', str(pe_tr))\n",
    "print('- Test:', str(pe_tst))\n",
    "\n",
    "# Compute Z_grid\n",
    "Z_grid = poly.fit_transform(X_grid)\n",
    "n_grid = Z_grid.shape[0]\n",
    "Zn, mz, sz = normalize(Z_grid[:,1:], mz, sz)\n",
    "Z_grid = np.concatenate((np.ones((n_grid,1)), Zn), axis=1)\n",
    "\n",
    "# Compute the classifier output for all samples in the grid.\n",
    "dd = LogReg.predict(Z_grid)\n",
    "pp = LogReg.predict_proba(Z_grid)[:,1]\n",
    "pp = pp.reshape(xx.shape)\n",
    "\n",
    "# Paint output maps\n",
    "pylab.rcParams['figure.figsize'] = 6, 6  # Set figure size\n",
    "\n",
    "plt.plot(x0c0, x1c0,'r.', label=labels[c0])\n",
    "plt.plot(x0c1, x1c1,'g+', label=labels[c1])\n",
    "plt.xlabel('$x_' + str(ind[0]) + '$')\n",
    "plt.ylabel('$x_' + str(ind[1]) + '$')\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.contourf(xx, yy, pp, cmap=plt.cm.copper)\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.contour(xx, yy, pp, levels=[0.5],\n",
    "                  colors='b', linewidths=(3,))\n",
    "\n",
    "plt.colorbar(CS, ticks=[0, 0.5, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
