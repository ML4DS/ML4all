{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Introduction to Classification.\n",
    "\n",
    "    Notebook version: 2.1 (Oct 19, 2018)\n",
    "\n",
    "    Author: Jesús Cid Sueiro (jcid@tsc.uc3m.es)\n",
    "            Jerónimo Arenas García (jarenas@tsc.uc3m.es)\n",
    "            \n",
    "    Changes: v.1.0 - First version. Extracted from a former notebook on K-NN\n",
    "             v.2.0 - Adapted to Python 3.0 (backcompatible with Python 2.7)\n",
    "             v.2.1 - Minor corrections affecting the notation and assumptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# To visualize plots in the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# Import some libraries that will be necessary for working with data and displaying plots\n",
    "import csv     # To read csv files\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from sklearn import neighbors, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. The Classification problem\n",
    "\n",
    "In a generic classification problem, we are given an observation vector ${\\bf x}\\in \\mathbb{R}^N$ which is known to belong to one and only one *category* or *class*, $y$, in the set ${\\mathcal Y} = \\{0, 1, \\ldots, M-1\\}$. The goal of a classifier system is to predict the value of $y$ based on ${\\bf x}$.\n",
    "\n",
    "To design the classifier, we are given a collection of labelled observations ${\\mathcal D} = \\{({\\bf x}^{(k)}, y^{(k)})\\}_{k=0}^{K-1}$ where, for each observation ${\\bf x}^{(k)}$, the value of its true category, $y^{(k)}$, is known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1. Binary Classification\n",
    "\n",
    "We will focus in binary classification problems, where the label set is binary, ${\\mathcal Y} = \\{0, 1\\}$. Despite its simplicity, this is the most frequent case. \n",
    "\n",
    "Many multi-class classification problems are usually solved by decomposing them into a collection of binary problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.2. The i.i.d. assumption.\n",
    "\n",
    "The classification algorithms, as many other machine learning algorithms, are based on two major underlying hypothesis:\n",
    "\n",
    "   - All samples in dataset ${\\mathcal D}$ have been generated by the same distribution $p_{{\\bf X}, Y}({\\bf x}, y)$.\n",
    "   - For any test data, the tuple formed by the input sample and its unknown class, $({\\bf x}, y)$, is an independent outcome of the *same* distribution.\n",
    "   \n",
    "These two assumptions are essential to have some guarantees that a classifier design based on ${\\mathcal D}$ has a good perfomance when applied to new input samples. Note that, despite assuming the existence of an underlying distribution, such distribution is unknown: otherwise, we could ignore ${\\mathcal D}$ and apply classic decision theory to find the optimal predictor based on  $p_{{\\bf X}, Y}({\\bf x}, y)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. A simple classification problem: the Iris dataset\n",
    "\n",
    "(Iris dataset presentation is based on this <a href=http://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/> Tutorial </a> by <a href=http://machinelearningmastery.com/about/> Jason Brownlee</a>) \n",
    "\n",
    "As an illustration, consider the <a href = http://archive.ics.uci.edu/ml/datasets/Iris> Iris dataset </a>, taken from the <a href=http://archive.ics.uci.edu/ml/> UCI Machine Learning repository </a>. Quoted from the dataset description:\n",
    "\n",
    "> This is perhaps the best known database to be found in the pattern recognition literature. The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. [...] One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. \n",
    "\n",
    "The *class* is the species, which is one of *setosa*, *versicolor* or *virginica*. Each instance contains 4 measurements of given flowers: sepal length, sepal width, petal length and petal width, all in centimeters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Taken from Jason Brownlee notebook.\n",
    "with open('datasets/iris.data', 'r') as csvfile:\n",
    "\tlines = csv.reader(csvfile)\n",
    "\tfor row in lines:\n",
    "\t\tprint(','.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next, we will split the data into a training dataset, that will be used to learn the classification model, and a test dataset that we can use to evaluate its the accuracy.\n",
    "\n",
    "We first need to convert the flower measures that were loaded as strings into numbers that we can work with. Next we need to split the data set **randomly** into train and datasets. A ratio of 67/33 for train/test will be used.\n",
    "\n",
    "The code fragment below defines a function `loadDataset` that loads the data in a CSV with the provided filename and splits it randomly into train and test datasets using the provided split ratio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Adapted from a notebook by Jason Brownlee\n",
    "def loadDataset(filename, split):\n",
    "    xTrain = []\n",
    "    cTrain = []\n",
    "    xTest = []\n",
    "    cTest = []\n",
    "\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "    for i in range(len(dataset)-1):\n",
    "        for y in range(4):\n",
    "            dataset[i][y] = float(dataset[i][y])\n",
    "        item = dataset[i]\n",
    "        if random.random() < split:\n",
    "            xTrain.append(item[0:-1])\n",
    "            cTrain.append(item[-1])\n",
    "        else:\n",
    "            xTest.append(item[0:-1])\n",
    "            cTest.append(item[-1])\n",
    "    return xTrain, cTrain, xTest, cTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can use this function to get a data split. Note that, because of the way samples are assigned to the train or test datasets, the number of samples in each partition will differ if you run the code several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "xTrain_all, cTrain_all, xTest_all, cTest_all = loadDataset('./datasets/iris.data', 0.67)\n",
    "nTrain_all = len(xTrain_all)\n",
    "nTest_all = len(xTest_all)\n",
    "print('Train:', str(nTrain_all))\n",
    "print('Test:', str(nTest_all))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To get some intuition about this four dimensional dataset we can plot 2-dimensional projections taking only two variables each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "i = 2 # Try 0,1,2,3\n",
    "j = 3 # Try 0,1,2,3 with j!=i\n",
    "\n",
    "# Take coordinates for each class separately\n",
    "xiSe = [xTrain_all[n][i] for n in range(nTrain_all) if cTrain_all[n]=='Iris-setosa']\n",
    "xjSe = [xTrain_all[n][j] for n in range(nTrain_all) if cTrain_all[n]=='Iris-setosa']\n",
    "xiVe = [xTrain_all[n][i] for n in range(nTrain_all) if cTrain_all[n]=='Iris-versicolor']\n",
    "xjVe = [xTrain_all[n][j] for n in range(nTrain_all) if cTrain_all[n]=='Iris-versicolor']\n",
    "xiVi = [xTrain_all[n][i] for n in range(nTrain_all) if cTrain_all[n]=='Iris-virginica']\n",
    "xjVi = [xTrain_all[n][j] for n in range(nTrain_all) if cTrain_all[n]=='Iris-virginica']\n",
    "\n",
    "plt.plot(xiSe, xjSe,'bx', label='Setosa')\n",
    "plt.plot(xiVe, xjVe,'r.', label='Versicolor')\n",
    "plt.plot(xiVi, xjVi,'g+', label='Virginica')\n",
    "plt.xlabel('$x_' + str(i) + '$')\n",
    "plt.ylabel('$x_' + str(j) + '$')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the following, we will design a classifier to separate classes \"Versicolor\" and \"Virginica\" using $x_0$ and $x_1$ only. To do so, we build a training set with samples from these categories, and a bynary label $y^{(k)} = 1$ for samples in class \"Virginica\", and $0$ for \"Versicolor\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Select two classes\n",
    "c0 = 'Iris-versicolor' \n",
    "c1 = 'Iris-virginica'\n",
    "\n",
    "# Select two coordinates\n",
    "ind = [0, 1]\n",
    "\n",
    "# Take training test\n",
    "X_tr = np.array([[xTrain_all[n][i] for i in ind] for n in range(nTrain_all) \n",
    "                  if cTrain_all[n]==c0 or cTrain_all[n]==c1])\n",
    "C_tr = [cTrain_all[n] for n in range(nTrain_all) \n",
    "          if cTrain_all[n]==c0 or cTrain_all[n]==c1]\n",
    "Y_tr = np.array([int(c==c1) for c in C_tr])\n",
    "n_tr = len(X_tr)\n",
    "\n",
    "# Take test set\n",
    "X_tst = np.array([[xTest_all[n][i] for i in ind] for n in range(nTest_all) \n",
    "                 if cTest_all[n]==c0 or cTest_all[n]==c1])\n",
    "C_tst = [cTest_all[n] for n in range(nTest_all) \n",
    "         if cTest_all[n]==c0 or cTest_all[n]==c1]\n",
    "Y_tst = np.array([int(c==c1) for c in C_tst])\n",
    "n_tst = len(X_tst)\n",
    "\n",
    "# Separate components of x into different arrays (just for the plots)\n",
    "x0c0 = [X_tr[n][0] for n in range(n_tr) if Y_tr[n]==0]\n",
    "x1c0 = [X_tr[n][1] for n in range(n_tr) if Y_tr[n]==0]\n",
    "x0c1 = [X_tr[n][0] for n in range(n_tr) if Y_tr[n]==1]\n",
    "x1c1 = [X_tr[n][1] for n in range(n_tr) if Y_tr[n]==1]\n",
    "\n",
    "# Scatterplot.\n",
    "labels = {'Iris-setosa': 'Setosa', \n",
    "          'Iris-versicolor': 'Versicolor',\n",
    "          'Iris-virginica': 'Virginica'}\n",
    "plt.plot(x0c0, x1c0,'r.', label=labels[c0])\n",
    "plt.plot(x0c1, x1c1,'g+', label=labels[c1])\n",
    "plt.xlabel('$x_' + str(ind[0]) + '$')\n",
    "plt.ylabel('$x_' + str(ind[1]) + '$')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. A Baseline Classifier: Maximum A Priori.\n",
    "\n",
    "For the selected data set, we have two clases and a dataset with the following class proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('Class 0 (' + c0 + '): ' + str(n_tr - sum(Y_tr)) + ' samples')\n",
    "print('Class 1 (' + c1 + '): ' + str(sum(Y_tr)) + ' samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The maximum a priori classifier assigns any sample ${\\bf x}$ to the most frequent class in the training set. Therefore, the class prediction $y$ for any sample ${\\bf x}$ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y = int(2*sum(Y_tr) > n_tr)\n",
    "print('y = ' + str(y) + ' (' + (c1 if y==1 else c0) + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The error rate for this baseline classifier is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Training and test error arrays\n",
    "E_tr = (Y_tr != y)\n",
    "E_tst = (Y_tst != y)\n",
    "\n",
    "# Error rates\n",
    "pe_tr = float(sum(E_tr)) / n_tr\n",
    "pe_tst = float(sum(E_tst)) / n_tst\n",
    "print('Pe(train):', str(pe_tr))\n",
    "print('Pe(test):', str(pe_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The error rate of the baseline classifier is a simple benchmark for classification. Since the maximum a priori decision is independent on the observation, ${\\bf x}$, any classifier based on ${\\bf x}$ should have a better (or, at least, not worse) performance than the baseline classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parametric vs non-parametric classification.\n",
    "\n",
    "Most classification algorithms can be fitted to one of two categories:\n",
    "\n",
    "1. Parametric classifiers: to classify any input sample ${\\bf x}$, the classifier applies some function $f_{\\bf w}({\\bf x})$ which depends on some parameters ${\\bf w}$. The training dataset is used to estimate ${\\bf w}$. Once the parameter has been estimated, the training data is no longer needed to classify new inputs.\n",
    "\n",
    "2. Non-parametric classifiers: the classifier decision for any input ${\\bf x}$ depend on the training data in a direct manner. The training data must be preserved to classify new data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
