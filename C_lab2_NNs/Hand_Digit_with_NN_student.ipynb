{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada593d9",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#-MNIST-Hand-Digit-Classification-\" data-toc-modified-id=\"-MNIST-Hand-Digit-Classification--1\"><font color=\"teal\"> MNIST Hand Digit Classification </font></a></span></li><li><span><a href=\"#-Part-1.-Scikit-learn-Methods-\" data-toc-modified-id=\"-Part-1.-Scikit-learn-Methods--2\"><font color=\"teal\"> Part 1. Scikit-learn Methods </font></a></span><ul class=\"toc-item\"><li><span><a href=\"#-1.-Data-Preparation-\" data-toc-modified-id=\"-1.-Data-Preparation--2.1\"><font color=\"teal\"> 1. Data Preparation </font></a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1.-Data-load\" data-toc-modified-id=\"1.1.-Data-load-2.1.1\">1.1. Data load</a></span></li><li><span><a href=\"#1.2.-Data-partitioning\" data-toc-modified-id=\"1.2.-Data-partitioning-2.1.2\">1.2. Data partitioning</a></span></li><li><span><a href=\"#1.3.-Data-normalization\" data-toc-modified-id=\"1.3.-Data-normalization-2.1.3\">1.3. Data normalization</a></span></li></ul></li><li><span><a href=\"#-2.-Binary-classification-\" data-toc-modified-id=\"-2.-Binary-classification--2.2\"><font color=\"teal\"> 2. Binary classification </font></a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1.-Two-dimensional-representation\" data-toc-modified-id=\"2.1.-Two-dimensional-representation-2.2.1\">2.1. Two dimensional representation</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.2.1.-Principal-Component-Analysis-(PCA)\" data-toc-modified-id=\"2.2.1.-Principal-Component-Analysis-(PCA)-2.2.1.1\">2.2.1. Principal Component Analysis (PCA)</a></span></li><li><span><a href=\"#2.2.2.-Linear-Classification-with-Logistic-Regression\" data-toc-modified-id=\"2.2.2.-Linear-Classification-with-Logistic-Regression-2.2.1.2\">2.2.2. Linear Classification with Logistic Regression</a></span></li><li><span><a href=\"#2.2.3.-Polynomial-Logistic-Regression\" data-toc-modified-id=\"2.2.3.-Polynomial-Logistic-Regression-2.2.1.3\">2.2.3. Polynomial Logistic Regression</a></span></li><li><span><a href=\"#2.2.4.-Multi-Layer-Perceptron\" data-toc-modified-id=\"2.2.4.-Multi-Layer-Perceptron-2.2.1.4\">2.2.4. Multi-Layer Perceptron</a></span></li></ul></li><li><span><a href=\"#2.2.-Classification-with-all-input-features\" data-toc-modified-id=\"2.2.-Classification-with-all-input-features-2.2.2\">2.2. Classification with all input features</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.2.1.-Logistic-Regression\" data-toc-modified-id=\"2.2.1.-Logistic-Regression-2.2.2.1\">2.2.1. Logistic Regression</a></span></li><li><span><a href=\"#2.2.2.-K-Nearest-Neighbors\" data-toc-modified-id=\"2.2.2.-K-Nearest-Neighbors-2.2.2.2\">2.2.2. K Nearest Neighbors</a></span></li><li><span><a href=\"#2.2.3.-Multi-Layer-Perceptron\" data-toc-modified-id=\"2.2.3.-Multi-Layer-Perceptron-2.2.2.3\">2.2.3. Multi-Layer Perceptron</a></span></li></ul></li></ul></li><li><span><a href=\"#-3.-Multi-Class-Classification-\" data-toc-modified-id=\"-3.-Multi-Class-Classification--2.3\"><font color=\"teal\"> 3. Multi Class Classification </font></a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1.-Principal-Component-Analysis-(PCA)\" data-toc-modified-id=\"3.1.-Principal-Component-Analysis-(PCA)-2.3.1\">3.1. Principal Component Analysis (PCA)</a></span></li><li><span><a href=\"#3.2.-Nearest-Neighbor-Method\" data-toc-modified-id=\"3.2.-Nearest-Neighbor-Method-2.3.2\">3.2. Nearest Neighbor Method</a></span></li><li><span><a href=\"#3.3.-Multi-Layer-Perceptron\" data-toc-modified-id=\"3.3.-Multi-Layer-Perceptron-2.3.3\">3.3. Multi-Layer Perceptron</a></span></li></ul></li></ul></li><li><span><a href=\"#-Part-2.-Implementing-Deep-Networks-with-PyTorch-\" data-toc-modified-id=\"-Part-2.-Implementing-Deep-Networks-with-PyTorch--3\"><font color=\"teal\"> Part 2. Implementing Deep Networks with PyTorch </font></a></span><ul class=\"toc-item\"><li><span><a href=\"#-4.-Pytorch-Tutorial-\" data-toc-modified-id=\"-4.-Pytorch-Tutorial--3.1\"><font color=\"teal\"> 4. Pytorch Tutorial </font></a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1.-PyTorch-Installation\" data-toc-modified-id=\"4.1.-PyTorch-Installation-3.1.1\">4.1. PyTorch Installation</a></span></li><li><span><a href=\"#4.2.-Torch-tensors-(very)-general-overview\" data-toc-modified-id=\"4.2.-Torch-tensors-(very)-general-overview-3.1.2\">4.2. Torch tensors (very) general overview</a></span></li><li><span><a href=\"#4.3.-Automatic-Gradient-Calculation\" data-toc-modified-id=\"4.3.-Automatic-Gradient-Calculation-3.1.3\">4.3. Automatic Gradient Calculation</a></span></li></ul></li><li><span><a href=\"#-5.-Feed-Forward-Networks-using-PyTorch-\" data-toc-modified-id=\"-5.-Feed-Forward-Networks-using-PyTorch--3.2\"><font color=\"teal\"> 5. Feed Forward Networks using PyTorch </font></a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1.-Using-torch-nn-module\" data-toc-modified-id=\"5.1.-Using-torch-nn-module-3.2.1\">5.1. Using torch <em>nn</em> module</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pvacO3ZY0ruw",
   "metadata": {
    "id": "pvacO3ZY0ruw"
   },
   "source": [
    "# <font color='teal'> MNIST Hand Digit Classification </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ioSe4IOP0poW",
   "metadata": {
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1636326152849,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "ioSe4IOP0poW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "size=18\n",
    "params = {'legend.fontsize': 'Large',\n",
    "          'axes.labelsize': size,\n",
    "          'axes.titlesize': size,\n",
    "          'xtick.labelsize': size*0.75,\n",
    "          'ytick.labelsize': size*0.75}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eZX0Au20x_5",
   "metadata": {
    "id": "8eZX0Au20x_5"
   },
   "source": [
    "In this notebook we will explore different strategies for solving a  classification problem consisting of determining the handwritten digit corresponding to a $ 28 \\times 28 $ pixel image (MNIST dataset).\n",
    "\n",
    "   - We will start by tackling a binary classification problem using different classification algorithms whose implementations are available in scikit-learn, including the multilayer perceptron as an example of a multilayer type neural network (multilayer perceptron, MLP).\n",
    "\n",
    "   - Next, we will consider multiclass classification, and calculate the performance of the previous algorithms in this more challenging problem.\n",
    "\n",
    "   - The last part of the notebook contains an introduction to [PyTorch](https://pytorch.org/), one of the most widely used libraries for neural network training. We will review the basic concepts of Pytorch and the different modules that allow simplifying the implementation and optimization of neural networks, including the design of convolutional neural networks (CNNs) that represent a more powerful alternative than MLPs in image classification problems.\n",
    "\n",
    "For faster executions you must run PyTorch code on GPU. For this, it is sufficient to use Gooble Colab by properly configuring the runtime environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pSgy6gZAvkfE",
   "metadata": {
    "id": "pSgy6gZAvkfE"
   },
   "source": [
    "# <font color='teal'> Part 1. Scikit-learn Methods </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YdZGSCKj3MXA",
   "metadata": {
    "id": "YdZGSCKj3MXA"
   },
   "source": [
    "## <font color='teal'> 1. Data Preparation </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9RIq0oUsnjJD",
   "metadata": {
    "id": "9RIq0oUsnjJD"
   },
   "source": [
    "### 1.1. Data load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q0VOVrnjiGx0",
   "metadata": {
    "id": "q0VOVrnjiGx0"
   },
   "source": [
    "MNIST is a handwritten digit classification problem that includes 60,000 training patterns and 10,000 test patterns, with representations obtained from the digitization of the corresponding grayscale images and with $28\\times 28$ pixel resolution.\n",
    "\n",
    "The database can be downloaded from the [OpenML repository](https://www.openml.org/) using tools available from Scikit-learn. It is recommended that after a first download you make a local copy of the data to speed up future executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pJFsqg8A3aQd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33697,
     "status": "ok",
     "timestamp": 1636326190890,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "pJFsqg8A3aQd",
    "outputId": "0a2b7dd0-c397-4ea9-9b20-142acd51efd7"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "# Format data in y as integers\n",
    "y = y.astype(np.int)\n",
    "\n",
    "print('Size of Input Data Matrix:', X.shape)\n",
    "print('Size of Label Vector:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ae5_EBPpjQ8z",
   "metadata": {
    "id": "Ae5_EBPpjQ8z"
   },
   "source": [
    "\n",
    "\n",
    "**Exercise 1.1:** Save data variables `X` and `y` so that you can use them in the future without donwloading the dataset again. Reload data from file to check the correctness of your solution \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UQmqMAGN4Tr8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2586,
     "status": "ok",
     "timestamp": 1636326194465,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "UQmqMAGN4Tr8",
    "outputId": "27c4dfb3-0b51-40eb-a6a1-3f0b6cbd7ed2"
   },
   "outputs": [],
   "source": [
    "# You may use numpy.savez\n",
    "# Reload variables with names Xlocal and ylocal\n",
    "\n",
    "# <SOL>\n",
    "# </SOL>\n",
    "\n",
    "# Check that the reloaded matrices shapes are the same as before\n",
    "print('Size of Input Data Matrix:', Xlocal.shape)\n",
    "print('Size of Label Vector:', ylocal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cZjFlwuemK55",
   "metadata": {
    "id": "cZjFlwuemK55"
   },
   "source": [
    "Each row of `X` contains a different digit. You can display the original images by realigning the dimensions of each row of `X`, as shown in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaQ4noc40V7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1636326194466,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "evaQ4noc40V7",
    "outputId": "9ce930e0-5598-439e-f13e-452af09c5029"
   },
   "outputs": [],
   "source": [
    "pos = 1900\n",
    "\n",
    "plt.imshow(X[pos,].reshape(28, 28)), plt.axis('off'), plt.show()\n",
    "print('The label of element %s is \"%s\"' % (pos, y[pos]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uFWLr8QqnqcH",
   "metadata": {
    "id": "uFWLr8QqnqcH"
   },
   "source": [
    "### 1.2. Data partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apYLkip1o23R",
   "metadata": {
    "id": "apYLkip1o23R"
   },
   "source": [
    "To begin, we will perform a random partition of the available data into training and test sets of 60,000 and 10,000 digits, respectively.\n",
    "\n",
    "The notebook also considers a binary problem consisting of the recognition of digits 7 and 9. We have selected this pair of digits as it is one of the most confusing, but if you wish, you can use any other pair of digits.\n",
    "\n",
    "**Exercise 1.2:** Create the binary classification problem 7 vs 9. Save the corresponding data matrices with names `X_tr_bin`, `y_tr_bin`, `X_tst_bin`, `y_tst_bin`. Make sure that the target vectors contain just 0s (for class 7) and 1s (class 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "go-R80Jh5ODw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1255,
     "status": "ok",
     "timestamp": 1636326195712,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "go-R80Jh5ODw",
    "outputId": "d51c090a-2823-47b3-a3bf-2d82179f47ef"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_samples = 60000\n",
    "test_samples = 10000\n",
    "\n",
    "X_tr, X_tst, y_tr, y_tst = train_test_split(\n",
    "    Xlocal, ylocal, train_size=train_samples, test_size=test_samples,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print('Shape of input training data (multiclass):', X_tr.shape)\n",
    "print('Shape of target training vector (multiclass):', y_tr.shape)\n",
    "print('Shape of input test data (multiclass):', X_tst.shape)\n",
    "print('Shape of target test vector (multiclass):', y_tst.shape)\n",
    "\n",
    "# Exercise: create the binary classification problem 7 vs 9\n",
    "# <SOL>\n",
    "# </SOL>\n",
    "\n",
    "print('\\nShape of input training data (binary):', X_tr_bin.shape)\n",
    "print('Shape of target training vector (binary):', y_tr_bin.shape)\n",
    "print('Shape of input test data (binary):', X_tst_bin.shape)\n",
    "print('Shape of target test vector (binary):', y_tst_bin.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t6lPtOXPsXOh",
   "metadata": {
    "id": "t6lPtOXPsXOh"
   },
   "source": [
    "### 1.3. Data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iIy3YPNXsa1t",
   "metadata": {
    "id": "iIy3YPNXsa1t"
   },
   "source": [
    "Next we will normalize the data for the multiclass and binary problems. When working with images, it is frequent to normalize the input data, corresponding to the gray intensity values of the different pixels, so that they take values in the range $[-0.5, 0.5]$.\n",
    "\n",
    "**Exercise 1.3:** Implement the normalization of the input data. Make sure to normalize data independently for the multiclass and binary classification cases. Make also sure not to refit the scaler object when transforming the test partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tQ3p5r6riZ4g",
   "metadata": {
    "executionInfo": {
     "elapsed": 466,
     "status": "ok",
     "timestamp": 1636326196175,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "tQ3p5r6riZ4g"
   },
   "outputs": [],
   "source": [
    "# <SOL>\n",
    "# </SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-Bnmq8Fct5Mp",
   "metadata": {
    "id": "-Bnmq8Fct5Mp"
   },
   "source": [
    "## <font color='teal'> 2. Binary classification </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C_NU6E8fwXGH",
   "metadata": {
    "id": "C_NU6E8fwXGH"
   },
   "source": [
    "### 2.1. Two dimensional representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tE62DVX4whjU",
   "metadata": {
    "id": "tE62DVX4whjU"
   },
   "source": [
    "In order to be able to represent the classification frontier, we will begin our exploration by working on the two variables that present the greatest dispersion. To do this, we will use the Principal Component Analysis (PCA) algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8IG9fDwLavil",
   "metadata": {
    "id": "8IG9fDwLavil"
   },
   "source": [
    "#### 2.2.1. Principal Component Analysis (PCA)\n",
    "\n",
    "**Exercise 2.1:** Obtain the first two PCA projections for the binary classification problem. Store your results in the variables `X_tr_2D` and` X_tst_2D`. Make a scatter plot of these dimensions distinguishing the points corresponding to both classes, and reflect on the type of classification frontier that would provide a lower error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QXGBXfL98b7O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "executionInfo": {
     "elapsed": 2368,
     "status": "ok",
     "timestamp": 1636309400146,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "QXGBXfL98b7O",
    "outputId": "763d141a-0fcb-47a7-82b6-233406587c3a"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# <SOL>\n",
    "# </SOL>\n",
    "\n",
    "plt.semilogx(C_param, CE_param)\n",
    "plt.xlabel('C'), plt.ylabel('(%)'), plt.title('Classification Error Rate (Linear Logistic Regression)')\n",
    "plt.show()\n",
    "\n",
    "print('CE of Linear Logistic Regression Classifier (%):', CE_LR2D)\n",
    "print('NLL of Linear Logistic Regression Classifier:', NLL_LR2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SOYth_tyF0nw",
   "metadata": {
    "id": "SOYth_tyF0nw"
   },
   "source": [
    "The next cell visualizes the classification border and the probabilistic map of the selected classifier (`clf`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xggzYojG7Q2U",
   "metadata": {
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1636238047706,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "xggzYojG7Q2U"
   },
   "outputs": [],
   "source": [
    "def plot_proba_map(X, y, clf):\n",
    "\n",
    "    # param X: Input Data Matrix (Size (N,2))\n",
    "    # param y: Targets (Size (N,))\n",
    "    # param clf: a classifier implementing the predict_proba method\n",
    "\n",
    "    if X.shape[1] != 2:\n",
    "        print('Can only plot 2D probability maps')\n",
    "    else:\n",
    "        # Create a regtangular grid.\n",
    "        x_min, x_max = X[:, 0].min(), X[:, 0].max() \n",
    "        y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
    "        dx = x_max - x_min\n",
    "        dy = y_max - y_min\n",
    "        h = dy /400\n",
    "        xx, yy = np.meshgrid(np.arange(x_min - 0.1 * dx, x_max + 0.1 * dx, h),\n",
    "                              np.arange(y_min - 0.1 * dx, y_max + 0.1 * dy, h))\n",
    "        X_grid = np.array([xx.ravel(), yy.ravel()]).T\n",
    "\n",
    "        # Compute the classifier output for all samples in the grid.\n",
    "        pp = clf.predict_proba(X_grid)[:,1]\n",
    "        pp = pp.reshape(xx.shape)\n",
    "\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        CS = plt.contourf(xx, yy, pp, cmap=plt.cm.copper)\n",
    "        plt.contour(CS, levels=[0.5], colors='m', linewidths=(3,))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        CS = plt.contourf(xx, yy, pp, cmap=plt.cm.copper)\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, s=4, cmap='summer')\n",
    "        plt.contour(CS, levels=[0.5], colors='m', linewidths=(3,))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399ccRoY0Qo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "executionInfo": {
     "elapsed": 1425,
     "status": "ok",
     "timestamp": 1636238071492,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "c399ccRoY0Qo",
    "outputId": "cc81beaf-4f89-468a-ac8e-f87ab338bad2"
   },
   "outputs": [],
   "source": [
    "plot_proba_map(X_tr_2D, y_tr_bin, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Sj3N0_GR4Nj0",
   "metadata": {
    "id": "Sj3N0_GR4Nj0"
   },
   "source": [
    "A relevant parameter for the training of logistic regression is the optimization method used to update the parameter vector $\\bf w$. You can try other methods different from the `lbfgs` method which is the default selection. You can find information about these methods online, for instance in this stackoverflow entry: [Logistic regression python solvers' definitions](https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k2GKhS-LNc_r",
   "metadata": {
    "id": "k2GKhS-LNc_r"
   },
   "source": [
    "#### 2.2.3. Polynomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genyAZcIoIsX",
   "metadata": {
    "id": "genyAZcIoIsX"
   },
   "source": [
    "A strategy for the implementation of classifiers that provide non-linear boundaries consists of transforming the input variables. To this end, in this section we will use polynomial transformations, exploring different values of the degree of the built-in terms to try to optimize performance.\n",
    "\n",
    "The proposed processing scheme for this section consists of the following steps:\n",
    "\n",
    "   - Polynomial expansion of the input variables using the `PolynomialFeatures` method of scikit-learn\n",
    "   - Scaling of all variables to zero mean and unit variance (`StandardScaler` method)\n",
    "   - Logistic regression\n",
    "\n",
    "The free parameters to be adjusted are, therefore, the degree of the polynomial transformation and the parameter $ C $ of the logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CGGx0qKtogwa",
   "metadata": {
    "id": "CGGx0qKtogwa"
   },
   "source": [
    "**Exercise 2.4**: Validate parameters `degree` and `C` of the proposed classification scheme using a 5-fold validation. Allow for polynomial transformations of degree up to 6. A very convenient way to do this is to define a processing pipeline in scikit-learn, and use it together with `GridSearchCV`.\n",
    "\n",
    "Note that both parameters should be validated together, i.e., all possible combinations need to be evaluated.\n",
    "\n",
    "For the next two cells to work, you need to use the following variable names:\n",
    "\n",
    "   - `clf`: Best classifier selected with 5 fold strategy. It needs to implement a `clf.predict_proba` method\n",
    "   - `CE_poly`: Average Classification Error Rate of previous classifier calculated over the test data\n",
    "   - `NLL_poly`: Negative log-lilelihood of previous classifier calculated over the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bf9clKZMNbI1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35089,
     "status": "ok",
     "timestamp": 1636242703697,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "Bf9clKZMNbI1",
    "outputId": "9a8aa8af-9d6a-444b-913f-ebf3b4b785aa"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# <SOL>\n",
    "# </SOL>\n",
    "\n",
    "print('CE of Polynomial Logistic Regression Classifier (%):', CE_poly)\n",
    "print('NLL of Polynomial Logistic Regression Classifier:', NLL_poly)\n",
    "print('Selected parameters:', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y_41WubvP2mt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "executionInfo": {
     "elapsed": 1325,
     "status": "ok",
     "timestamp": 1636242711605,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "Y_41WubvP2mt",
    "outputId": "73818299-aa0f-4fe8-f999-87273b8c99c3"
   },
   "outputs": [],
   "source": [
    "plot_proba_map(X_tr_2D, y_tr_bin, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C6oV1jXvP5sV",
   "metadata": {
    "id": "C6oV1jXvP5sV"
   },
   "source": [
    "#### 2.2.4. Multi-Layer Perceptron\n",
    "\n",
    "Rather than using a predefined type of transformation, such as polynomial, we can recur to neural networks with non-linear activation functions to learn the most appropriate representation of the input data to solve the classification problem.\n",
    "\n",
    "**Exercise 2.5:** In this section you will use the `MLPClassifier method` provided by scikit-learn for the implementation of feed-forward networks. You will only need to adjust the following parameters:\n",
    "\n",
    "   - `activation`: The activation function for the units of the intermediate layer. You can test `relu` and `tanh`.\n",
    "   - `max_iter`: Number of iterations of the optimization method. Try different values and make sure that the algorithm has completely converged.\n",
    "   - `hidden_layer_sizes`: Use just one hidden layer with 20 units\n",
    "   - `alpha`: The L2 regularization parameters.\n",
    "\n",
    "Save your results using the following variable names:\n",
    "\n",
    "   - `clf`: Best classifier selected with 5 fold strategy. It needs to implement a `clf.predict_proba` method\n",
    "   - `CE_MLP`: Average Classification Error Rate of previous classifier calculated over the test data\n",
    "   - `NLL_MLP`: Negative log-lilelihood of previous classifier calculated over the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ExmaXdhCTQxl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159145,
     "status": "ok",
     "timestamp": 1636309580008,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "ExmaXdhCTQxl",
    "outputId": "b0871ee7-11f1-465f-8cd0-a05898fe6133"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# <SOL>\n",
    "# </SOL>\n",
    "\n",
    "print('CE of MLP Classifier (%):', CE_MLP)\n",
    "print('NLL of MLP Classifier:', NLL_MLP)\n",
    "print('Selected parameters:', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Su8gQGI0ZgYv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "executionInfo": {
     "elapsed": 1413,
     "status": "ok",
     "timestamp": 1636243402205,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "Su8gQGI0ZgYv",
    "outputId": "78567fa7-9a8f-4399-9189-c0de92daa74a"
   },
   "outputs": [],
   "source": [
    "plot_proba_map(X_tr_2D, y_tr_bin, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_sOedcIrP5ve",
   "metadata": {
    "id": "_sOedcIrP5ve"
   },
   "source": [
    "### 2.2. Classification with all input features\n",
    "\n",
    "**Exercise 2.6:** Analyze the performance in the binary classification problem of the following classifiers: \n",
    "\n",
    "   - Logistic regression (validate $C$)\n",
    "   - K-nearest neighbors (validate $K$)\n",
    "   - Multi-layer perceptron (validate size of hidden layers)\n",
    "\n",
    "For comparison purposes you can use both the average classifiation error rate and the negative log-likelihood. \n",
    "\n",
    "In this section you need to use all 784 available features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MVs5s-pFP55_",
   "metadata": {
    "id": "MVs5s-pFP55_"
   },
   "source": [
    "#### 2.2.1. Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WdJ5-j_zu0iy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "executionInfo": {
     "elapsed": 281892,
     "status": "ok",
     "timestamp": 1636310214828,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "WdJ5-j_zu0iy",
    "outputId": "5d897f26-0806-4a01-bfda-e8653fa3de4d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# <SOL>\n",
    "# </SOL>\n",
    "\n",
    "plt.semilogx(C_param, CE_param)\n",
    "plt.xlabel('C'), plt.ylabel('(%)'), plt.title('Classification Error Rate (Linear Logistic Regression)')\n",
    "plt.show()\n",
    "\n",
    "print('CE of Linear Logistic Regression Classifier (%):', CE_LR)\n",
    "print('NLL of Linear Logistic Regression Classifier:', NLL_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gAqQXl3_uYr0",
   "metadata": {
    "id": "gAqQXl3_uYr0"
   },
   "source": [
    "#### 2.2.2. K Nearest Neighbors\n",
    "\n",
    "Be aware that, in this case, the number of test samples together with the dimension of the input data implies long processing times for classification (close to 1 min per execution in Google Colab). You might consider to subsample the test partition for the validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcgknXiu1Lk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1911296,
     "status": "ok",
     "timestamp": 1636279319011,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "9dcgknXiu1Lk",
    "outputId": "a40b25e7-954b-4f9e-de04-cf0de88e684e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# <SOL>\n",
    "# </SOL>\n",
    "\n",
    "plt.plot(K_param, CE_param)\n",
    "plt.xlabel('K'), plt.ylabel('(%)'), plt.title('Classification Error Rate (KNN)')\n",
    "plt.show()\n",
    "\n",
    "print('CE of KNN (%):', CE_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O6ErAvgkuYvL",
   "metadata": {
    "id": "O6ErAvgkuYvL"
   },
   "source": [
    "#### 2.2.3. Multi-Layer Perceptron\n",
    "\n",
    "Be aware that, in this case, the number of test samples together with the dimension of the input data implies long processing times for classification (close to 1 min per execution in Google Colab). You might consider to subsample the test partition for the validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MaQenA33u15-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3026802,
     "status": "ok",
     "timestamp": 1636313410361,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "MaQenA33u15-",
    "outputId": "5218af52-e2a5-41dd-ea70-cb4cb90fb3cc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# <SOL>\n",
    "# </SOL>\n",
    "\n",
    "print('CE of MLP Classifier (%):', CE_MLP)\n",
    "print('NLL of MLP Classifier:', NLL_MLP)\n",
    "print('Selected parameters:', clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DCS-ejARuYxp",
   "metadata": {
    "id": "DCS-ejARuYxp"
   },
   "source": [
    "## <font color='teal'> 3. Multi Class Classification </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Z-im408BD7E",
   "metadata": {
    "id": "1Z-im408BD7E"
   },
   "source": [
    "In this section we will train classification schemes that allow us to discriminate between the 10 digits that make up the complete dataset. In this case, you must use the parameters provided, and you will be asked to study the execution times required by the different methods. To do this, you can use the `time` library as follows:\n",
    "\n",
    "```\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "#Some code should go here\n",
    "etime = time.time() - start\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b-G225JTttR7",
   "metadata": {
    "id": "b-G225JTttR7"
   },
   "source": [
    "### 3.1. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WMb-VBAYEa7v",
   "metadata": {
    "id": "WMb-VBAYEa7v"
   },
   "source": [
    "In a preliminary way, and as you did in section 2.2.1, we can analyze the first two PCA components of the available data. You can see that in this case there is a very important overlap between the digits of all the classes on the first two components of PCA.\n",
    "\n",
    "In this section, we will apply the different classification strategies **using all the available features**.\n",
    "\n",
    "**Exercise 3.1:** Analyze the variance of the successive projections that the PCA method would obtain, and reflect on whether a smaller-dimensional representation of the input data could be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4GbmPimxdYk2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "executionInfo": {
     "elapsed": 5409,
     "status": "ok",
     "timestamp": 1636316665167,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "4GbmPimxdYk2",
    "outputId": "96724578-21be-48de-e5f0-004a84d1a527"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(2)  # project from 784 to 2 dimensions\n",
    "projected = pca.fit_transform(X_tr)\n",
    "plt.scatter(projected[:, 0], projected[:, 1],\n",
    "            c=y_tr, edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.cm.get_cmap('rainbow', 10))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M6ZNXyCCCyHK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "executionInfo": {
     "elapsed": 7244,
     "status": "ok",
     "timestamp": 1636316804138,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "M6ZNXyCCCyHK",
    "outputId": "5d523dd6-e703-4fe2-e750-65edf23f204b"
   },
   "outputs": [],
   "source": [
    "# Solution to Exercise 3.1\n",
    "\n",
    "# <SOL>\n",
    "# </SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eD_lCq1tzY2",
   "metadata": {
    "id": "6eD_lCq1tzY2"
   },
   "source": [
    "### 3.2. Nearest Neighbor Method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xd6g04YFN-dr",
   "metadata": {
    "id": "xd6g04YFN-dr"
   },
   "source": [
    "In this section, you will analyze the performance of the nearest neighbor (1-NN) algorithm. The complexity of this algorithm grows with the size of the training set, so it is proposed to analyze the behavior of the algorithm for a variable size of the training set.\n",
    "\n",
    "**Exercise 3.2:** Use the 1-NN method with a varying training set size. Obtain for each size:\n",
    "\n",
    "   - The average classifiation error rate calculated on the test set\n",
    "   - The fit time for the 1-NN method\n",
    "   - The time taken to classify the complete test partition (10000 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12yjxKyVBJPb",
   "metadata": {
    "id": "12yjxKyVBJPb"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "\n",
    "train_size = [250, 500, 1000, 2000, 5000, 10000, 25000, 60000]\n",
    "fit_time = []\n",
    "test_time = []\n",
    "CE = []\n",
    "\n",
    "for ntrain in train_size:\n",
    "    print('Classifying with', ntrain, 'samples')\n",
    "    # <SOL>\n",
    "    # </SOL>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LC-Atn_RF7xh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1636319935586,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "LC-Atn_RF7xh",
    "outputId": "3ccd6f5b-051b-4f59-cf24-d72364fc789e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,3.5))\n",
    "plt.subplot(1, 3, 1), plt.plot(train_size, 100*CE), plt.xlabel('Training Set Size'), plt.ylabel('(%)'), plt.title('CE')\n",
    "plt.subplot(1, 3, 2), plt.plot(train_size, fit_time), plt.xlabel('Training Set Size'), plt.ylabel('Seconds'), plt.title('Fit Time')\n",
    "plt.subplot(1, 3, 3), plt.plot(train_size, test_time), plt.xlabel('Training Set Size'), plt.ylabel('Seconds'), plt.title('Test Time')\n",
    "plt.show()\n",
    "print('Average Classification Error for the 1-NN approach', 100*np.min(CE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upmPdC-sPavl",
   "metadata": {
    "id": "upmPdC-sPavl"
   },
   "source": [
    "**Exercise 3.3:** Calculate the confusion matrix of the 1-NN classifier when using 1000 samples for the training set, and answer the following questions:\n",
    "   - Which two digits are most frequently confused?\n",
    "   - Which is the digit that gets misclassified most often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tGEWM259P5B3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "executionInfo": {
     "elapsed": 18776,
     "status": "ok",
     "timestamp": 1636320930450,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "tGEWM259P5B3",
    "outputId": "d606c5b7-f523-41c9-a64f-3a84885767b9"
   },
   "outputs": [],
   "source": [
    "# <SOL>\n",
    "# </SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OO_gKc7vt8tG",
   "metadata": {
    "id": "OO_gKc7vt8tG"
   },
   "source": [
    "### 3.3. Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FXrJj8xukfwz",
   "metadata": {
    "id": "FXrJj8xukfwz"
   },
   "source": [
    "**Exercise 3.4:** Train an MLP network using all samples in the training set. Use the following settings: \n",
    "   - `relu` activation function for the hidden units \n",
    "   - Two hidden layers with 200 and 100 neurons, respectively\n",
    "   - Maximum number of iterations for the training: 2000 iterations\n",
    "   \n",
    "Compare the performance of the MLP network with that of the 1-NN method. Consider in your comparison both the classification error rate and the fit and operation times.\n",
    "\n",
    "Calculate also the negative log likelihood of the model implemente by the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82iWWpbDYEMK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 249659,
     "status": "ok",
     "timestamp": 1636325828946,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "82iWWpbDYEMK",
    "outputId": "c17516dc-ee93-430f-afe7-f41db880ae81"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "\n",
    "MLP = MLPClassifier(activation='relu', max_iter=2000, hidden_layer_sizes=(200,100))\n",
    "\n",
    "# <SOL>\n",
    "# </SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aAexovhj3VQS",
   "metadata": {
    "id": "aAexovhj3VQS"
   },
   "source": [
    "## <font color='teal'> 5. Feed Forward Networks using PyTorch </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ogmdp2B8t3PO",
   "metadata": {
    "id": "ogmdp2B8t3PO"
   },
   "source": [
    "### 5.1. Using torch *nn* module\n",
    "\n",
    "PyTorch *nn* module provides many attributes and methods to make simple the implementation and training of Neural Networks\n",
    "\n",
    "* ```nn.Module``` and ```nn.Parameter``` allow to implement a more concise training loop\n",
    "\n",
    "* ```nn.Module``` is a PyTorch class that will be used to encapsulate and design a specific neural network, thus, it is central to the implementation of deep neural nets using PyTorch\n",
    "\n",
    "* ```nn.Parameter``` allow the definition of trainable network parameters. In this way, we will simplify the implementation of the training loop.\n",
    "\n",
    "* All parameters defined with ```nn.Parameter``` will have ```requires_grad = True```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aoAGCAD42xE4",
   "metadata": {
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1636328176621,
     "user": {
      "displayName": "JERONIMO ARENAS GARCIA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOssjUa3TkcZfTRodRH00CbPGuyuJ_qQjeMOwM=s64",
      "userId": "13981211833123710399"
     },
     "user_tz": -60
    },
    "id": "aoAGCAD42xE4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "#Convert to Torch tensors\n",
    "X_tr_torch = torch.from_numpy(X_tr)\n",
    "X_val_torch = torch.from_numpy(X_tst)\n",
    "#Note we are using One Hot Encoding for the labels\n",
    "y_tr_torch = torch.from_numpy(lb.fit_transform(y_tr))\n",
    "y_val_torch = torch.from_numpy(lb.transform(y_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Jb7rEYPjxdzu",
   "metadata": {
    "id": "Jb7rEYPjxdzu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Hand_Digit_with_NN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
